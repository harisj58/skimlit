{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5F23inAaxKuT"
   },
   "source": [
    "# Milestone Project: SkimLit ðŸ“„ðŸ”¥\n",
    "\n",
    "In the previous notebook ([NLP fundamentals in TensorFlow](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb)), we went through some fundamental natural lanuage processing concepts. The main ones being **tokenzation** (turning words into numbers) and **creating embeddings** (creating a numerical representation of words).\n",
    "\n",
    "In this project, we're going to be putting what we've learned into practice.\n",
    "\n",
    "More specificially, we're going to be replicating the deep learning model behind the 2017 paper [*PubMed 200k RCT: a Dataset for Sequenctial Sentence Classification in Medical Abstracts*](https://arxiv.org/abs/1710.06071).\n",
    "\n",
    "When it was released, the paper presented a new dataset called PubMed 200k RCT which consists of ~200,000 labelled Randomized Controlled Trial (RCT) abstracts.\n",
    "\n",
    "The goal of the dataset was to explore the ability for NLP models to classify sentences which appear in sequential order.\n",
    "\n",
    "In other words, given the abstract of a RCT, what role does each sentence serve in the abstract?\n",
    "\n",
    "![Skimlit example inputs and outputs](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/09-skimlit-overview-input-and-output.png)\n",
    "\n",
    "*Example inputs ([harder to read abstract from PubMed](https://pubmed.ncbi.nlm.nih.gov/28942748/)) and outputs ([easier to read abstract](https://pubmed.ncbi.nlm.nih.gov/32537182/)) of the model we're going to build. The model will take an abstract wall of text and predict the section label each sentence should have.*  \n",
    "\n",
    "### Model Input\n",
    "\n",
    "For example, can we train an NLP model which takes the following input (note: the following sample has had all numerical symbols replaced with \"@\"):\n",
    "\n",
    "> To investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ). A total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks. Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers. Pain was assessed using the visual analog pain scale ( @-@ mm ).\n",
    "Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ).,\n",
    "Serum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured.\n",
    "There was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks. The mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively. Further , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group. These differences remained significant at @ weeks. The Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ). Low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ).\n",
    "\n",
    "### Model output\n",
    "\n",
    "And returns the following output:\n",
    "\n",
    "```\n",
    "['###24293578\\n',\n",
    " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
    " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
    " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
    " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
    " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
    " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
    " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
    " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
    " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
    " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
    " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
    " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
    " '\\n']\n",
    " ```\n",
    "\n",
    "### Problem in a sentence\n",
    "\n",
    "The number of RCT papers released is continuing to increase, those without structured abstracts can be hard to read and in turn slow down researchers moving through the literature. \n",
    "\n",
    "### Solution in a sentence\n",
    "\n",
    "Create an NLP model to classify abstract sentences into the role they play (e.g. objective, methods, results, etc)  to enable researchers to skim through the literature (hence SkimLit ðŸ¤“ðŸ”¥) and dive deeper when necessary.\n",
    "\n",
    "> ðŸ“– **Resources:** Before going through the code in this notebook, you might want to get a background of what we're going to be doing. To do so, spend an hour (or two) going through the following papers and then return to this notebook:\n",
    "1. Where our data is coming from: [*PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts*](https://arxiv.org/abs/1710.06071)\n",
    "2. Where our model is coming from: [*Neural networks for joint sentence\n",
    "classification in medical paper abstracts*](https://arxiv.org/pdf/1612.05251.pdf).\n",
    "\n",
    "## Credits\n",
    "\n",
    "This notebook was made possible by the help of an excellent tutor, [Mr. Daniel Bourke](https://github.com/mrdbourke) through his excellent course [TensorFlow Developer Certificate in 2023: Zero to Mastery](https://www.udemy.com/course/tensorflow-developer-certificate-machine-learning-zero-to-mastery/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6KzbfQ5xfRC"
   },
   "source": [
    "## Confirm access to a GPU\n",
    "\n",
    "Since we're going to be building deep learning models, let's make sure we have a GPU.\n",
    "\n",
    "In Google Colab, you can set this up by going to Runtime -> Change runtime type -> Hardware accelerator -> GPU.\n",
    "\n",
    "If you don't have access to a GPU, the models we're building here will likely take up to 10x longer to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H1vL5GbZx4xp",
    "outputId": "c66b7ca9-8b72-471e-f6fc-a53ca3e773bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 3060 (UUID: GPU-92ece648-2a5b-27e9-5631-77fe94146258)\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdOWNwIwx6Ni"
   },
   "source": [
    "## Get data\n",
    "\n",
    "Before we can start building a model, we've got to download the PubMed 200k RCT dataset.\n",
    "\n",
    "In a phenomenal act of kindness, the authors of the paper have made the data they used for their research availably publically and for free in the form of .txt files [on GitHub](https://github.com/Franck-Dernoncourt/pubmed-rct).\n",
    "\n",
    "We can copy them to our local directory using `git clone https://github.com/Franck-Dernoncourt/pubmed-rct`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uoeSNy7bx8QB",
    "outputId": "4330eb6d-28d1-4166-c958-9047e70cd93b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'pubmed-rct' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
    "!cd pubmed-rct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_oVFPARx976"
   },
   "source": [
    "Checking the contents of the downloaded repository, you can see there are four folders.\n",
    "\n",
    "Each contains a different version of the PubMed 200k RCT dataset.\n",
    "\n",
    "Looking at the [README file](https://github.com/Franck-Dernoncourt/pubmed-rct) from the GitHub page, we get the following information:\n",
    "* PubMed 20k is a subset of PubMed 200k. I.e., any abstract present in PubMed 20k is also present in PubMed 200k.\n",
    "* `PubMed_200k_RCT` is the same as `PubMed_200k_RCT_numbers_replaced_with_at_sign`, except that in the latter all numbers had been replaced by `@`. (same for `PubMed_20k_RCT` vs. `PubMed_20k_RCT_numbers_replaced_with_at_sign`).\n",
    "* Since Github file size limit is 100 MiB, we had to compress `PubMed_200k_RCT\\train.7z` and `PubMed_200k_RCT_numbers_replaced_with_at_sign\\train.zip`. To uncompress `train.7z`, you may use 7-Zip on Windows, Keka on Mac OS X, or p7zip on Linux.\n",
    "\n",
    "To begin with, the dataset we're going to be focused on is `PubMed_20k_RCT_numbers_replaced_with_at_sign`.\n",
    "\n",
    "Why this one?\n",
    "\n",
    "Rather than working with the whole 200k dataset, we'll keep our experiments quick by starting with a smaller subset. We could've chosen the dataset with numbers instead of having them replaced with `@` but we didn't.\n",
    "\n",
    "Let's check the file contents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "INq6_s5EyDgR",
    "outputId": "4bbf10b0-8991-4ff7-e9e6-d9ca028d1638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is Local Disk\n",
      " Volume Serial Number is 24FC-0D16\n",
      "\n",
      " Directory of D:\\Machine Learning Projects\\skimlit\\pubmed-rct\\PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
      "\n",
      "13-03-2023  07.46 PM    <DIR>          .\n",
      "13-03-2023  07.46 PM    <DIR>          ..\n",
      "13-03-2023  07.46 PM         4,880,409 dev.txt\n",
      "13-03-2023  07.46 PM         4,846,504 test.txt\n",
      "13-03-2023  07.46 PM        29,118,832 train.txt\n",
      "               3 File(s)     38,845,745 bytes\n",
      "               2 Dir(s)  149,454,262,272 bytes free\n"
     ]
    }
   ],
   "source": [
    "# Check what files are in the PubMed_20K dataset \n",
    "!dir \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAz6CG80yJeB"
   },
   "source": [
    "Beautiful, looks like we've got three separate text files:\n",
    "* `train.txt` - training samples.\n",
    "* `dev.txt` - dev is short for development set, which is another name for validation set (in our case, we'll be using and referring to this file as our validation set).\n",
    "* `test.txt` - test samples.\n",
    "\n",
    "To save ourselves typing out the filepath to our target directory each time, let's turn it into a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "WT00y1OXyNmh"
   },
   "outputs": [],
   "source": [
    "# Start by using the 20k dataset\n",
    "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7oNK8g6myP3B",
    "outputId": "0bf2859c-6f5d-4681-f6ff-b7439f6a75a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
       " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all of the filenames in the target directory\n",
    "import os\n",
    "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZo7dRGtyR1Z"
   },
   "source": [
    "## Preprocess data\n",
    "\n",
    "Okay, now we've downloaded some text data, do you think we're ready to model it?\n",
    "\n",
    "Wait...\n",
    "\n",
    "We've downloaded the data but we haven't even looked at it yet.\n",
    "\n",
    "What's the motto for getting familiar with any new dataset?\n",
    "\n",
    "I'll give you a clue, the word begins with \"v\" and we say it three times.\n",
    "\n",
    "> Vibe, vibe, vibe?\n",
    "\n",
    "Sort of... we've definitely got to the feel the vibe of our data.\n",
    "\n",
    "> Values, values, values?\n",
    "\n",
    "Right again, we want to *see* lots of values but not quite what we're looking for.\n",
    "\n",
    "> Visualize, visualize, visualize?\n",
    "\n",
    "Boom! That's it. To get familiar and understand how we have to prepare our data for our deep learning models, we've got to visualize it.\n",
    "\n",
    "Because our data is in the form of text files, let's write some code to read each of the lines in a target file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "kvp4K51Yyqgy"
   },
   "outputs": [],
   "source": [
    "# Create function to read the lines of a document\n",
    "def get_lines(filename):\n",
    "  \"\"\"\n",
    "  Reads filename (a text filename) and returns the lines of text as a list.\n",
    "\n",
    "  Args:\n",
    "    filename: a string containing the target filepath.\n",
    "\n",
    "  Returns:\n",
    "    A list of strings with one string per line from the target filename.\n",
    "  \"\"\"\n",
    "  with open(filename, 'r') as file:\n",
    "    return file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FNnfQLv_0Zkg",
    "outputId": "d6752868-cc2c-4374-c54c-1614a574d475"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['###24293578\\n',\n",
       " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
       " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
       " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
       " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
       " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
       " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
       " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
       " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
       " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
       " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
       " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
       " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
       " '\\n',\n",
       " '###24854809\\n',\n",
       " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
       " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
       " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
       " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
       " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in the training lines\n",
    "train_lines = get_lines(data_dir+\"train.txt\") # read the lines with the training file\n",
    "train_lines[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7Y3h1540p1Z",
    "outputId": "11029034-6305-4132-bfce-72138316b12a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210040"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fwnD4rE05FR"
   },
   "source": [
    "Let's think about how we want our data to look like...\n",
    "\n",
    "How I think our data would be best represented...\n",
    "\n",
    "```\n",
    "[\n",
    "  {'line number': 0,\n",
    "   'target': 'BACKGROUND',\n",
    "   'text': 'Emotional eating is associated with overeating and the development of obesity.\\n',\n",
    "   'total_lines': 11},\n",
    "   ...]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zb4LkO9B1szi"
   },
   "source": [
    "Reading the lines from the training text file results in a list of strings containing different abstract samples, the sentences in a sample along with the role the sentence plays in the abstract.\n",
    "\n",
    "The role of each sentence is prefixed at the start of each line separated by a tab (`\\t`) and each sentence finishes with a new line (`\\n`).\n",
    "\n",
    "Different abstracts are separated by abstract ID's (lines beginning with `###`) and newlines (`\\n`).\n",
    "\n",
    "Knowing this, it looks like we've got a couple of steps to do to get our samples ready to pass as training data to our future machine learning model.\n",
    "\n",
    "Let's write a function to perform the following steps:\n",
    "* Take a target file of abstract samples.\n",
    "* Read the lines in the target file.\n",
    "* For each line in the target file:  \n",
    "  * If the line begins with `###` mark it as an abstract ID and the beginning of a new abstract.\n",
    "    * Keep count of the number of lines in a sample.\n",
    "  * If the line begins with `\\n` mark it as the end of an abstract sample.\n",
    "    * Keep count of the total lines in a sample.\n",
    "  * Record the text before the `\\t` as the label of the line.\n",
    "  * Record the text after the `\\t` as the text of the line.\n",
    "* Return all of the lines in the target text file as a list of dictionaries containing the key/value pairs:\n",
    "  * `\"line_number\"` - the position of the line in the abstract (e.g. `3`).\n",
    "  * `\"target\"` - the role of the line in the abstract (e.g. `OBJECTIVE`).\n",
    "  * `\"text\"` - the text of the line in the abstract.\n",
    "  * `\"total_lines\"` - the total lines in an abstract sample (e.g. `14`).\n",
    "* Abstract ID's and newlines should be omitted from the returned preprocessed data.\n",
    "\n",
    "Example returned preprocessed sample (a single line from an abstract):\n",
    "\n",
    "```\n",
    "[{'line_number': 0,\n",
    "  'target': 'OBJECTIVE',\n",
    "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
    "  'total_lines': 11},\n",
    "  ...]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "3ZBGBMoF2KVy"
   },
   "outputs": [],
   "source": [
    "def preprocess_text_with_line_numbers(filename):\n",
    "  \"\"\"\n",
    "  Returns a list of dictionaries of abstract line data.\n",
    "\n",
    "  Takes in filename, reads its contents and sorts through each line,\n",
    "  extracting things like the target label, the text of the sentence,\n",
    "  how many sentences are in the current abstract and what sentence,\n",
    "  number the target line is.\n",
    "  \"\"\"\n",
    "  input_lines = get_lines(filename) # get all lines from filename\n",
    "  abstract_lines = \"\" # create an empty abstract\n",
    "  abstract_samples = [] # create an empty list of abstracts\n",
    "\n",
    "  # Loop through each line in the target line\n",
    "  for line in input_lines:\n",
    "    if line.startswith(\"###\"):  # check to see if line is an ID line\n",
    "      abstract_id = line\n",
    "      abstract_lines = \"\" # reset abstract string\n",
    "    elif line.isspace():  # check to see if line is a new line\n",
    "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
    "\n",
    "      # Iterate through each line in a single abstract and count them at the same time\n",
    "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
    "        line_data = {}  # create empty dict to store data from line\n",
    "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
    "        line_data['target'] = target_text_split[0]  # get target label\n",
    "        line_data['text'] = target_text_split[1].lower()  # get target text and lower it\n",
    "        line_data['line_number'] = abstract_line_number # what number line does the line appear in the abstract?\n",
    "        line_data['total_lines'] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n",
    "        abstract_samples.append(line_data) # how many total lines are in the abstract? (start from 0)\n",
    "\n",
    "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
    "      abstract_lines += line\n",
    "\n",
    "  return abstract_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful! That's one good looking function. Let's use it to preprocess each of our RCT 20k datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYJtv3cW5ZHq",
    "outputId": "70fe4444-db26-4be7-b65b-d901d6102b1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180040 30212 30135\n"
     ]
    }
   ],
   "source": [
    "# Get data from file and preprocess it\n",
    "%timeit\n",
    "train_samples = preprocess_text_with_line_numbers(data_dir+'train.txt')\n",
    "val_samples = preprocess_text_with_line_numbers(data_dir+'dev.txt')\n",
    "test_samples = preprocess_text_with_line_numbers(data_dir+'test.txt')\n",
    "print(len(train_samples), len(val_samples), len(test_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do our training samples look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6DuuuAaF58KD",
    "outputId": "b9289afe-9273-4dc2-affa-9d5837e091c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 'OBJECTIVE',\n",
       "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       "  'line_number': 2,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       "  'line_number': 3,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       "  'line_number': 4,\n",
       "  'total_lines': 11},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
       "  'line_number': 5,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
       "  'line_number': 6,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       "  'line_number': 7,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
       "  'line_number': 8,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'these differences remained significant at @ weeks .',\n",
       "  'line_number': 9,\n",
       "  'total_lines': 11},\n",
       " {'target': 'RESULTS',\n",
       "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
       "  'line_number': 10,\n",
       "  'total_lines': 11},\n",
       " {'target': 'CONCLUSIONS',\n",
       "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
       "  'line_number': 11,\n",
       "  'total_lines': 11},\n",
       " {'target': 'BACKGROUND',\n",
       "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 10},\n",
       " {'target': 'BACKGROUND',\n",
       "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 10}]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first abstract of our training data\n",
    "train_samples[:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ypp9E346JJT"
   },
   "source": [
    "Fantastic! Looks like our `preprocess_text_with_line_numbers()` function worked great. \n",
    "\n",
    "How about we turn our list of dictionaries into pandas DataFrame's so we visualize them better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "5enBWfep6rZT",
    "outputId": "8265644c-c2b5-4ae8-ae36-fdb3ff90967b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>there was a clinically relevant reduction in t...</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>the mean difference between treatment arms ( @...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>further , there was a clinically relevant redu...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>these differences remained significant at @ we...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>the outcome measures in rheumatology clinical ...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>emotional eating is associated with overeating...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>yet , empirical evidence for individual ( trai...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text  \\\n",
       "0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
       "1       METHODS  a total of @ patients with primary knee oa wer...   \n",
       "2       METHODS  outcome measures included pain reduction and i...   \n",
       "3       METHODS  pain was assessed using the visual analog pain...   \n",
       "4       METHODS  secondary outcome measures included the wester...   \n",
       "5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n",
       "6       RESULTS  there was a clinically relevant reduction in t...   \n",
       "7       RESULTS  the mean difference between treatment arms ( @...   \n",
       "8       RESULTS  further , there was a clinically relevant redu...   \n",
       "9       RESULTS  these differences remained significant at @ we...   \n",
       "10      RESULTS  the outcome measures in rheumatology clinical ...   \n",
       "11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n",
       "12   BACKGROUND  emotional eating is associated with overeating...   \n",
       "13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n",
       "\n",
       "    line_number  total_lines  \n",
       "0             0           11  \n",
       "1             1           11  \n",
       "2             2           11  \n",
       "3             3           11  \n",
       "4             4           11  \n",
       "5             5           11  \n",
       "6             6           11  \n",
       "7             7           11  \n",
       "8             8           11  \n",
       "9             9           11  \n",
       "10           10           11  \n",
       "11           11           11  \n",
       "12            0           10  \n",
       "13            1           10  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.DataFrame(train_samples)\n",
    "val_df = pd.DataFrame(val_samples)\n",
    "test_df = pd.DataFrame(test_samples)\n",
    "train_df.head(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is in DataFrame form, we can perform some data analysis on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSjqXZDa69LM",
    "outputId": "2029e620-8159-4dcf-ebff-8598b3d87ad3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "METHODS        59353\n",
       "RESULTS        57953\n",
       "CONCLUSIONS    27168\n",
       "BACKGROUND     21727\n",
       "OBJECTIVE      13839\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of labels in training data\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like sentences with the `OBJECTIVE` label are the least common.\n",
    "\n",
    "How about we check the distribution of our abstract lengths?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "OldQOe9w7Ouq",
    "outputId": "6b32c951-e4bf-4181-f5e4-df2985196995"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Length of different lines\n",
    "train_df.total_lines.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, looks like most of the abstracts are around 7 to 15 sentences in length.\n",
    "\n",
    "It's good to check these things out to make sure when we do train a model or test it on unseen samples, our results aren't outlandish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81J8TfoH7WwL"
   },
   "source": [
    "### Get lists of sentences\n",
    "\n",
    "When we build our deep learning model, one of its main inputs will be a list of strings (the lines of an abstract).\n",
    "\n",
    "We can get these easily from our DataFrames by calling the `tolist()` method on our `\"text\"` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9UR61UM27fd7",
    "outputId": "acd67035-d024-4050-f5f0-7862cbdf8c01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180040, 30212, 30135)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert abstract text lines into lists\n",
    "train_sentences = train_df['text'].tolist()\n",
    "val_sentences = val_df['text'].tolist()\n",
    "test_sentences = test_df['text'].tolist()\n",
    "len(train_sentences), len(val_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oc0l9Anb8Ef0",
    "outputId": "cf57f634-0cbb-41e6-e536-9c3012fae33a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
       " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
       " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
       " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
       " 'these differences remained significant at @ weeks .']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 10 lines of training sentences\n",
    "train_sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we've separated our text samples. As you might've guessed, we'll have to write code to convert the text to numbers before we can use it with our machine learning models, we'll get to this soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7T8XIhW68dYs"
   },
   "source": [
    "## Make numeric labels (ML models require numeric labels)\n",
    "\n",
    "We're going to create one hot and label encoded labels.\n",
    "\n",
    "We could get away with just making label encoded labels, however, TensorFlow's CategoricalCrossentropy loss function likes to have one hot encoded labels (this will enable us to use label smoothing later on).\n",
    "\n",
    "To numerically encode labels we'll use Scikit-Learn's [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) and [`LabelEncoder`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UAEUR089bjk",
    "outputId": "d6f685ee-0974-4f09-d7c5-a752c695ad95"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Machine Learning Projects\\skimlit\\env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encode labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False) # we want non-sparse matrix\n",
    "train_labels_one_hot = one_hot_encoder.fit_transform(train_df.target.to_numpy().reshape(-1, 1))\n",
    "val_labels_one_hot = one_hot_encoder.transform(val_df.target.to_numpy().reshape(-1, 1))\n",
    "test_labels_one_hot = one_hot_encoder.transform(test_df.target.to_numpy().reshape(-1, 1))\n",
    "\n",
    "# Check what one hot encoded labels look like\n",
    "val_labels_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXFVYhkP-5Fc"
   },
   "source": [
    "### Label encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPI0BhIJ-IVc",
    "outputId": "82fcfc48-4fb1-4bb3-a5d4-c23e42e03f61"
   },
   "outputs": [],
   "source": [
    "# Extract labels ('target' columns) and encode them into integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train_labels_encoded = le.fit_transform(train_df.target.to_numpy())\n",
    "val_labels_encoded = le.transform(val_df.target.to_numpy())\n",
    "test_labels_encoded = le.transform(test_df.target.to_numpy())\n",
    "\n",
    "# Check what training labels look like\n",
    "train_labels_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've trained an instance of `LabelEncoder`, we can get the class names and number of classes using the `classes_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wuDWwzrB-pRc",
    "outputId": "fcf1f963-239e-4dca-a48f-7b9ec89be52a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class names and number of classes from LabelEncoder instance\n",
    "num_classes = len(le.classes_)\n",
    "class_names = le.classes_\n",
    "num_classes, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apWn7kqR_0_r"
   },
   "source": [
    "## Creating a series of model experiments\n",
    "\n",
    "We've proprocessed our data so now, in true machine learning fashion, it's time to setup a series of modelling experiments.\n",
    "\n",
    "We'll start by creating a simple baseline model to obtain a score we'll try to beat by building more and more complex models as we move towards replicating the sequence model outlined in [*Neural networks for joint sentence\n",
    "classification in medical paper abstracts*](https://arxiv.org/pdf/1612.05251.pdf).\n",
    "\n",
    "For each model, we'll train it on the training data and evaluate it on the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IkwMWIg6L0A"
   },
   "source": [
    "## Model 0: Getting a baseline \n",
    "\n",
    "Our first model we'll be a TF-IDF Multinomial Naive Bayes as recommended by [Scikit-Learn's machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n",
    "\n",
    "To build it, we'll create a Scikit-Learn `Pipeline` which uses the [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) class to convert our abstract sentences to numbers using the TF-IDF (term frequency-inverse document frequecy) algorithm and then learns to classify our sentences using the [`MultinomialNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) aglorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "tgeDTlea6PMj",
    "outputId": "a10580bc-da7d-4d73-b5e6-c0afef6eb2a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tf-idf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tf-idf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tf-idf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline\n",
    "model_0 = Pipeline([\n",
    "    ('tf-idf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(X=train_sentences,\n",
    "            y=train_labels_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the speed of the Multinomial Naive Bayes algorithm, it trains very quickly.\n",
    "\n",
    "We can evaluate our model's accuracy on the validation dataset using the `score()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxSMZ2Rr65iX",
    "outputId": "91e4fe42-95d2-4fa9-9db6-253370b4fcdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7218323844829869"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate our baseline model on validation data\n",
    "model_0.score(X=val_sentences, y=val_labels_encoded) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Looks like 72.1% accuracy will be the number to beat with our deeper models.\n",
    "\n",
    "Now let's make some predictions with our baseline model to further evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IE0zMutc7PJj",
    "outputId": "aa570763-9a64-468b-aed2-d6c1fb990982"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 3, ..., 4, 4, 1])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions using our baseline model\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our baseline's predictions, we'll import the `calculate_results()` function we created in the [previous notebook](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb) and added it to our [`helper_functions.py` script](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/helper_functions.py) to compare them to the ground truth labels.\n",
    "\n",
    "More specificially the `calculate_results()` function will help us obtain the following:\n",
    "* Accuracy\n",
    "* Precision\n",
    "* Recall\n",
    "* F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xk4TB3uS7bmq"
   },
   "source": [
    "### Download helper functions script\n",
    "\n",
    "Let's get our `helper_functions.py` script we've been using to store helper functions we've created in previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vJI09s-W7zS7",
    "outputId": "4ee47b62-bbf5-4974-9c9b-3ef6e4fb58e2"
   },
   "outputs": [],
   "source": [
    "# !curl -JLO https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "saVgBPe78FZB"
   },
   "outputs": [],
   "source": [
    "from helper_functions import calculate_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got the helper functions script we can import the `caculate_results()` function and see how our baseline model went."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JglE0LX18Mc3",
    "outputId": "b41ad665-54a6-4ae9-98e6-c827bc576576"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.1832384482987,\n",
       " 'precision': 0.7186466952323352,\n",
       " 'recall': 0.7218323844829869,\n",
       " 'f1': 0.6989250353450294}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate baseline results\n",
    "baseline_results = calculate_results(val_labels_encoded, baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jq7kzGtk8xyU"
   },
   "source": [
    "## Preparing our data for deep sequence models\n",
    "\n",
    "Excellent! We've got a working baseline to try and improve upon.\n",
    "\n",
    "But before we start building deeper models, we've got to create vectorization and embedding layers.\n",
    "\n",
    "The vectorization layer will convert our text to numbers and the embedding layer will capture the relationships between those numbers.\n",
    "\n",
    "To start creating our vectorization and embedding layers, we'll need to import the appropriate libraries (namely TensorFlow and NumPy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "Azk2c3Cr86nn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we'll be turning our sentences into numbers, it's a good idea to figure out how many words are in each sentence.\n",
    "\n",
    "When our model goes through our sentences, it works best when they're all the same length (this is important for creating batches of the same size tensors).\n",
    "\n",
    "For example, if one sentence is eight words long and another is 29 words long, we want to pad the eight word sentence with zeros so it ends up being the same length as the 29 word sentence.\n",
    "\n",
    "Let's write some code to find the average length of sentences in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbMFp6aJ9d7E",
    "outputId": "94813822-8d8e-4546-d23e-fc4d0dfd580a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.338269273494777"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long is each sentence on average?\n",
    "sent_len = [len(sentence.split()) for sentence in train_sentences]\n",
    "avg_sent_len = np.mean(sent_len)\n",
    "avg_sent_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about the distribution of sentence lengths?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "tIAPUZQ190kN",
    "outputId": "763e6613-7dc0-4fd0-fd80-56bb5985fbed"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What's the distribution look like?\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(sent_len, bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the vast majority of sentences are between 0 and 50 tokens in length.\n",
    "\n",
    "We can use NumPy's [`percentile`](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html) to find the value which covers 95% of the sentence lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOTHVrS4-PV7",
    "outputId": "3341adfb-3dbe-47de-cb02-d09b77e67efe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long of a sentence length covers 95% of examples?\n",
    "output_seq_len = int(np.percentile(sent_len, 95))\n",
    "output_seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful! It looks like 95% of the sentences in our training set have a length of 55 tokens or less.\n",
    "\n",
    "When we create our tokenization layer, we'll use this value to turn all of our sentences into the same length. Meaning sentences with a length below 55 get padded with zeros and sentences with a length above 55 get truncated (words after 55 get cut off).\n",
    "\n",
    "> ðŸ¤” **Question:** Why 95%?\n",
    "\n",
    "> **Answer:** So that our tokenization layer covers almost all the training examples. The ones that remain won't necessarily improve our results and would rather increase the space required to map the extra tokens.\n",
    "\n",
    "We could use the max sentence length of the sentences in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOevL-9M-wU5",
    "outputId": "8ea04fd6-fe4f-4a7c-88d5-bc7bf0d9626e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum sequence length in the training set\n",
    "max(sent_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, since hardly any sentences even come close to the max length, it would mean the majority of the data we pass to our model would be zeros (sinces all sentences below the max length would get padded with zeros).\n",
    "\n",
    "> ðŸ”‘ **Note:** The steps we've gone through are good practice when working with a text corpus for a NLP problem. You want to know how long your samples are and what the distribution of them is. See section 4 Data Analysis of the [PubMed 200k RCT paper](https://arxiv.org/pdf/1710.06071.pdf) for further examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create text vectorizer\n",
    "\n",
    "Now we've got a little more information about our texts, let's create a way to turn it into numbers.\n",
    "\n",
    "To do so, we'll use the [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) layer from TensorFlow.\n",
    "\n",
    "We'll keep all the parameters default except for `max_tokens` (the number of unique words in our dataset) and `output_sequence_length` (our desired output length for each vectorized sentence).\n",
    "\n",
    "Section 3.2 of the [PubMed 200k RCT paper](https://arxiv.org/pdf/1710.06071.pdf) states the vocabulary size of the PubMed 20k dataset as 68,000. So we'll use that as our `max_tokens` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "UNfK2x06_c5F"
   },
   "outputs": [],
   "source": [
    "# How many words are in our vocab? (taken from table 2 in: https://arxiv.org/pdf/1710.06071.pdf)\n",
    "max_tokens = 68000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And since discovered a sentence length of 55 covers 95% of the training sentences, we'll use that as our `output_sequence_length` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtaXXSyOAHrf"
   },
   "outputs": [],
   "source": [
    "# Create text vectorizer \n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "tv = TextVectorization(max_tokens=max_tokens,  # number of words in vocabulary\n",
    "                    output_sequence_length=output_seq_len)  # desired output length of vectorized sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Looks like our `text_vectorizer` is ready, let's adapt it to the training data (let it read the training data and figure out what number should represent what word) and then test it out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "IstcRfuOAviO"
   },
   "outputs": [],
   "source": [
    "# Adapt text vectorizer to training sentences\n",
    "tv.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1a0I4pkA8Kz",
    "outputId": "a1185098-d558-4501-db44-c9cbedcd2236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "according to national comprehensive cancer network ( nccn ) prognostic classification , patients were divided into a favourable group ( @ % ) , intermediate group ( @ % ) and unfavourable group ( @ % ) .\n",
      "\n",
      "Length of sentence: 203\n",
      "\n",
      "Vectorized text: [[  374     6   708  1417   135  2094 51567  1151  1911    12     9   471\n",
      "    143     8  3603    13  2122    13     3 10122    13     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# Test out text vectorizer on random sentences\n",
    "import random\n",
    "target_sentence = random.choice(train_sentences)\n",
    "print(f'Text:\\n{target_sentence}')\n",
    "print(f'\\nLength of sentence: {len(target_sentence)}')\n",
    "print(f'\\nVectorized text: {tv([target_sentence])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, we've now got a way to turn our sequences into numbers.\n",
    "\n",
    "> ðŸ›  **Exercise:** Try running the cell above a dozen or so times. What do you notice about sequences with a length less than 55?\n",
    "\n",
    "Using the [`get_vocabulary()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) method of our `text_vectorizer` we can find out a few different tidbits about our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RzNEaUYQBlQw",
    "outputId": "04737df6-4229-4cf1-9c43-ec1ac62a1416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 64841\n",
      "Most common words in vocab: ['', '[UNK]', 'the', 'and', 'of']\n",
      "Least common words in vocab: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
     ]
    }
   ],
   "source": [
    "# How many words in our training vocabulary?\n",
    "rct_20k_text_vocab = tv.get_vocabulary()\n",
    "print(f'Number of words in vocab: {len(rct_20k_text_vocab)}')\n",
    "print(f'Most common words in vocab: {rct_20k_text_vocab[:5]}')\n",
    "print(f'Least common words in vocab: {rct_20k_text_vocab[-5:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we wanted to figure out the configuration of our `text_vectorizer` we can use the `get_config()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZGrHfRzuCVDa",
    "outputId": "d4add140-732e-4e77-e691-bf842f0c8dbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'text_vectorization_1',\n",
       " 'trainable': True,\n",
       " 'dtype': 'string',\n",
       " 'batch_input_shape': (None,),\n",
       " 'max_tokens': 68000,\n",
       " 'standardize': 'lower_and_strip_punctuation',\n",
       " 'split': 'whitespace',\n",
       " 'ngrams': None,\n",
       " 'output_mode': 'int',\n",
       " 'output_sequence_length': 55,\n",
       " 'pad_to_max_tokens': False,\n",
       " 'sparse': False,\n",
       " 'ragged': False,\n",
       " 'vocabulary': None,\n",
       " 'idf_weights': None,\n",
       " 'encoding': 'utf-8'}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the config of our text vectorizer\n",
    "tv.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tf0TEC8CvPA"
   },
   "source": [
    "### Create custom text embedding\n",
    "\n",
    "Our `token_vectorization` layer maps the words in our text directly to numbers. However, this doesn't necessarily capture the relationships between those numbers.\n",
    "\n",
    "To create a richer numerical representation of our text, we can use an **embedding**.\n",
    "\n",
    "As our model learns (by going through many different examples of abstract sentences and their labels), it'll update its embedding to better represent the relationships between tokens in our corpus.\n",
    "\n",
    "We can create a trainable embedding layer using TensorFlow's [`Embedding`](https://www.tensorflow.org/tutorials/text/word_embeddings) layer.\n",
    "\n",
    "Once again, the main parameters we're concerned with here are the inputs and outputs of our `Embedding` layer.\n",
    "\n",
    "The `input_dim` parameter defines the size of our vocabulary. And the `output_dim` parameter defines the dimension of the embedding output.\n",
    "\n",
    "Once created, our embedding layer will take the integer outputs of our `text_vectorization` layer as inputs and convert them to feature vectors of size `output_dim`.\n",
    "\n",
    "Let's see it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "dR_NswFwDHLi"
   },
   "outputs": [],
   "source": [
    "# Create token embedding layer\n",
    "token_embed = layers.Embedding(input_dim=len(rct_20k_text_vocab), # length of vocabulary\n",
    "                               output_dim=128, # Note: different embedding sizes result in drastically different numbers of parameters to train\n",
    "                               mask_zero=True, # Use masking to handle variable sequence lengths (save space)\n",
    "                               name='token_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lUl6QPD6ErLM",
    "outputId": "5b6906ff-b5c5-4f5b-fe2d-de2627df4972"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence before vectorization:\n",
      "according to national comprehensive cancer network ( nccn ) prognostic classification , patients were divided into a favourable group ( @ % ) , intermediate group ( @ % ) and unfavourable group ( @ % ) .\n",
      "\n",
      "Sentence after vectorization:\\m[[  374     6   708  1417   135  2094 51567  1151  1911    12     9   471\n",
      "    143     8  3603    13  2122    13     3 10122    13     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n",
      "\n",
      "Sentence after embedding:\n",
      "[[[-0.04922863  0.00676526  0.04144059 ... -0.00084972 -0.01058438\n",
      "    0.00962917]\n",
      "  [-0.03577161  0.00329132 -0.00164508 ... -0.04126536  0.04649757\n",
      "    0.02811983]\n",
      "  [-0.02133771 -0.03323549  0.00501217 ...  0.00878064  0.04262474\n",
      "    0.0364431 ]\n",
      "  ...\n",
      "  [ 0.03279377 -0.02429336  0.03776551 ... -0.02981446  0.04063224\n",
      "   -0.02564217]\n",
      "  [ 0.03279377 -0.02429336  0.03776551 ... -0.02981446  0.04063224\n",
      "   -0.02564217]\n",
      "  [ 0.03279377 -0.02429336  0.03776551 ... -0.02981446  0.04063224\n",
      "   -0.02564217]]]\n",
      "\n",
      "Embedded sentence shape:\n",
      "(1, 55, 128)\n"
     ]
    }
   ],
   "source": [
    "# Show example embedding\n",
    "print(f'Sentence before vectorization:\\n{target_sentence}\\n')\n",
    "vectorized_sentence = tv([target_sentence])\n",
    "print(f'Sentence after vectorization:\\m{vectorized_sentence}\\n')\n",
    "embedded_sentence = token_embed(vectorized_sentence)\n",
    "print(f'Sentence after embedding:\\n{embedded_sentence}\\n')\n",
    "print(f'Embedded sentence shape:\\n{embedded_sentence.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IdBO7GoFbrF"
   },
   "source": [
    "## Create datasets (as fast as possible)\n",
    "\n",
    "We've gone through all the trouble of preprocessing our datasets to be used with a machine learning model, however, there are still a few steps we can use to make them work faster with our models.\n",
    "\n",
    "Namely, the `tf.data` API provides methods which enable faster data loading.\n",
    "\n",
    "> ðŸ“– **Resource:** For best practices on data loading in TensorFlow, check out the following:\n",
    "* [tf.data: Build TensorFlow input pipelines](https://www.tensorflow.org/guide/data)\n",
    "* [Better performance with the tf.data API](https://www.tensorflow.org/guide/data_performance)\n",
    "\n",
    "The main steps we'll want to use with our data is to turn it into a `PrefetchDataset` of batches.\n",
    "\n",
    "Doing so we'll ensure TensorFlow loads our data onto the GPU as fast as possible, in turn leading to faster training time.\n",
    "\n",
    "To create a batched `PrefetchDataset` we can use the methods [`batch()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch) and [`prefetch()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch), the parameter [`tf.data.AUTOTUNE`](https://www.tensorflow.org/api_docs/python/tf/data#AUTOTUNE) will also allow TensorFlow to determine the optimal amount of compute to use to prepare datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "xIKKFffmLUBf"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9wP5SVbmKqy9",
    "outputId": "6fc07074-3b80-4db4-f06e-260495bbf200"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn our data into TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRmz98j_LLQR",
    "outputId": "0e567638-88f7-4bc1-b042-98d31d3656fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take TensorSliceDatasets and turn them into prefetched datasets\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H61uu1eOMIf3"
   },
   "source": [
    "## Model 1: Conv1D with token embeddings\n",
    "\n",
    "Alright, we've now got a way to numerically represent our text and labels, time to build a series of deep models to try and improve upon our baseline.\n",
    "\n",
    "All of our deep models will follow a similar structure:\n",
    "\n",
    "```\n",
    "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
    "```\n",
    "\n",
    "The main component we'll be changing throughout is the `Layers` component. Because any modern deep NLP model requires text to be converted into an embedding before meaningful patterns can be discovered within.\n",
    "\n",
    "The first model we're going to build is a 1-dimensional Convolutional Neural Network. \n",
    "\n",
    "We're also going to be following the standard machine learning workflow of:\n",
    "- Build model\n",
    "- Train model\n",
    "- Evaluate model (make predictions and compare to ground truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "4Ks82D81MWMd"
   },
   "outputs": [],
   "source": [
    "# Create 1D conv model to process sequences\n",
    "inputs = layers.Input(shape=(1, ), dtype=tf.string)\n",
    "text_vectors = tv(inputs)\n",
    "token_embeddings = token_embed(text_vectors)  # vectorize text inputs\n",
    "x = layers.Conv1D(64, kernel_size=5, padding='same', activation='relu')(token_embeddings) # create embedding\n",
    "x = layers.GlobalAveragePooling1D()(x)  # condense the output of our feature vector from conv layer\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "OuVSY8oXN3os"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 55)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " token_embedding (Embedding)  (None, 55, 128)          8299648   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 55, 64)            41024     \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,340,997\n",
      "Trainable params: 8,340,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful! We've got our first deep sequence model built and ready to go. \n",
    "\n",
    "Checking out the model summary, you'll notice the majority of the trainable parameters are within the embedding layer. If we were to increase the size of the embedding (by increasing the `output_dim` parameter of the `Embedding` layer), the number of trainable parameters would increase dramatically.\n",
    "\n",
    "It's time to fit our model to the training data but we're going to make a mindful change.\n",
    "\n",
    "Since our training data contains nearly 200,000 sentences, fitting a deep model may take a while even with a GPU. So to keep our experiments swift, we're going to run them on a subset of the training dataset.\n",
    "\n",
    "More specifically, we'll only use the first 10% of batches (about 18,000 samples) of the training set to train on and the first 10% of batches from the validation set to validate on.\n",
    "\n",
    "> ðŸ”‘ **Note:** It's a standard practice in machine learning to test your models on smaller subsets of data first to make sure they work before scaling them to larger amounts of data. You should aim to run many smaller experiments rather than only a handful of large experiments. And since your time is limited, one of the best ways to run smaller experiments is to reduce the amount of data you're working with (10% of the full dataset is usually a good amount, as long as it covers a similar distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "uwZKq1ThN5HW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 36s 63ms/step - loss: 0.9180 - accuracy: 0.6354 - val_loss: 0.6842 - val_accuracy: 0.7424\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 35s 62ms/step - loss: 0.6586 - accuracy: 0.7563 - val_loss: 0.6341 - val_accuracy: 0.7693\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 37s 66ms/step - loss: 0.6198 - accuracy: 0.7729 - val_loss: 0.5973 - val_accuracy: 0.7829\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history_1 = model_1.fit(train_dataset,\n",
    "                        steps_per_epoch=int(0.1*len(train_dataset)),\n",
    "                        epochs=3,\n",
    "                        validation_data=valid_dataset,\n",
    "                        validation_steps=int(0.1*len(valid_dataset))) # only validate on 10% of batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brilliant! We've got our first trained deep sequence model, and it didn't take too long (and if we didn't prefetch our batched data, it would've taken longer).\n",
    "\n",
    "Time to make some predictions with our model and then evaluate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "jr2QwHtJOnUc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 3s 3ms/step - loss: 0.6000 - accuracy: 0.7840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5999578237533569, 0.7840262055397034]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on whole validation dataset\n",
    "model_1.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "cIk-7gVNPEQx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 3s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[4.2405698e-01, 1.7303471e-01, 7.3235631e-02, 3.0843386e-01,\n",
       "         2.1238791e-02],\n",
       "        [4.4881421e-01, 2.9579183e-01, 1.0973154e-02, 2.3718256e-01,\n",
       "         7.2381352e-03],\n",
       "        [1.2680741e-01, 3.6600754e-03, 1.4682044e-03, 8.6804229e-01,\n",
       "         2.2026827e-05],\n",
       "        ...,\n",
       "        [2.2203208e-06, 6.2418007e-04, 6.7642349e-04, 3.2760620e-06,\n",
       "         9.9869388e-01],\n",
       "        [6.4131051e-02, 4.8369399e-01, 8.1227049e-02, 7.5813316e-02,\n",
       "         2.9513457e-01],\n",
       "        [1.8870570e-01, 6.3835782e-01, 6.3329346e-02, 3.7437707e-02,\n",
       "         7.2169371e-02]], dtype=float32),\n",
       " (30212, 5))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions (our model gives us pred probs)\n",
    "model_1_pred_probs = model_1.predict(valid_dataset)\n",
    "model_1_pred_probs, model_1_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "c4Md4hPAPWCQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1], dtype=int64)>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert pred probs to classes\n",
    "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
    "model_1_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "-1gYLuJuRxzz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.40262147491063,\n",
       " 'precision': 0.7810736722762787,\n",
       " 'recall': 0.7840262147491063,\n",
       " 'f1': 0.7818423880389147}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 results\n",
    "model_1_results = calculate_results(val_labels_encoded, model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "tEW3DqMwSJ6i"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.1832384482987,\n",
       " 'precision': 0.7186466952323352,\n",
       " 'recall': 0.7218323844829869,\n",
       " 'f1': 0.6989250353450294}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjZMQcNYSP6k"
   },
   "source": [
    "## Model 2: Feature extraction with pretrained token embeddings\n",
    "\n",
    "Training our own embeddings took a little while to run, slowing our experiments down.\n",
    "\n",
    "Since we're moving towards replicating the model architecture in [*Neural Networks for Joint Sentence Classification\n",
    "in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf), it mentions they used a [pretrained GloVe embedding](https://nlp.stanford.edu/projects/glove/) as a way to initialise their token embeddings.\n",
    "\n",
    "To emulate this, let's see what results we can get with the [pretrained Universal Sentence Encoder embeddings from TensorFlow Hub](https://tfhub.dev/google/universal-sentence-encoder/4).\n",
    "\n",
    "> ðŸ”‘ **Note:** We could use GloVe embeddings as per the paper but since we're working with TensorFlow, we'll use what's available from TensorFlow Hub (GloVe embeddings aren't). We'll save [using pretrained GloVe embeddings](https://keras.io/examples/nlp/pretrained_word_embeddings/) as an extension.\n",
    "\n",
    "The model structure will look like:\n",
    "\n",
    "```\n",
    "Inputs (string) -> Pretrained embeddings from TensorFlow Hub (Universal Sentence Encoder) -> Layers -> Output (prediction probabilities)\n",
    "```\n",
    "\n",
    "You'll notice the lack of tokenization layer we've used in a previous model. This is because the Universal Sentence Encoder (USE) takes care of tokenization for us.\n",
    "\n",
    "This type of model is called transfer learning, or more specifically, **feature extraction transfer learning**. In other words, taking the patterns a model has learned elsewhere and applying it to our own problem.\n",
    "\n",
    "![TensorFlow Hub Universal Feature Encoder feature extractor model we're building](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/09-model-tf-hub-USE-to-dense-layer.png)\n",
    "*The feature extractor model we're building using a pretrained embedding from TensorFlow Hub.*\n",
    "\n",
    "To download the pretrained USE into a layer we can use in our model, we can use the [`hub.KerasLayer`](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer) class.\n",
    "\n",
    "We'll keep the pretrained embeddings frozen (by setting `trainable=False`) and add a trainable couple of layers on the top to tailor the model outputs to our own data.\n",
    "\n",
    "> ðŸ”‘ **Note:** Due to having to download a relatively large model (~916MB), the cell below may take a little while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1h1PyBQNub1b",
    "outputId": "b53eeaf3-e11e-42dd-df9b-3ea55423d81a"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        trainable=False,\n",
    "                                        name='universal_sentence_encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful, now our pretrained USE is downloaded and instantiated as a `hub.KerasLayer` instance, let's test it out on a random sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6GKc6DLvcgf",
    "outputId": "abea267f-6507-4a8a-b701-ad856908bd7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Sentence:\n",
      "@ ; @:@ -@ ) , which investigated client-treatment matching effects for alcohol treatment among outpatient ( n = @ ) and aftercare ( n = @ ) participants randomized to cognitive behavioral treatment ( cbt ) , @-step facilitation ( tsf ) , or motivational enhancement therapy ( met ) .\n",
      "\n",
      "Sentence after embedding:\n",
      "[ 0.04964988 -0.06070976 -0.02988971 -0.06933717 -0.06799664 -0.00830786\n",
      "  0.04268363  0.00856938 -0.000168   -0.01567342  0.07217481 -0.04471647\n",
      "  0.05988841  0.00699683 -0.04999425 -0.07092251 -0.07266004  0.02115776\n",
      " -0.06589364 -0.04557878  0.07101074  0.06098034  0.00304001 -0.04424376\n",
      "  0.00682835  0.00169661  0.04266669 -0.05211509 -0.04136244 -0.01151093]\n",
      "\n",
      "Length of sentence embedding: 512\n"
     ]
    }
   ],
   "source": [
    "# Test out the pretrained embedding on a random sentence\n",
    "random_train_sentence = random.choice(train_sentences)\n",
    "print(f\"Random Sentence:\\n{random_train_sentence}\\n\")\n",
    "use_embedded_sentence = tf_hub_embedding_layer([random_train_sentence])\n",
    "print(f'Sentence after embedding:\\n{use_embedded_sentence[0][:30]}\\n')\n",
    "print(f'Length of sentence embedding: {len(use_embedded_sentence[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! As we mentioned before the pretrained USE module from TensorFlow Hub takes care of tokenizing our text for us and outputs a 512 dimensional embedding vector.\n",
    "\n",
    "Let's put together and compile a model using our `tf_hub_embedding_layer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TA5J7DCwwIaK"
   },
   "source": [
    "### Building and fitting an NLP feature extraction model using pretrained embeddings from TensorFlow Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "yTZ8CdB0wyD7"
   },
   "outputs": [],
   "source": [
    "# Define feature extraction model using TF Hub layer\n",
    "inputs = layers.Input(shape=[], dtype=tf.string)\n",
    "pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize and embed all in one\n",
    "x = layers.Dense(128, activation='relu')(pretrained_embedding)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "model_2 = tf.keras.Model(inputs,\n",
    "                         outputs,\n",
    "                         name=\"model_2_USE_feature_extractor\")\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "-yiaYDH5xzHw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_USE_feature_extractor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " universal_sentence_encoder   (None, 512)              256797824 \n",
      " (KerasLayer)                                                    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,864,133\n",
      "Trainable params: 66,309\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the summary of our model we can see there's a large number of total parameters, however, the majority of these are non-trainable. This is because we set `training=False` when we instatiated our USE feature extractor layer.\n",
    "\n",
    "So when we train our model, only the top two output layers will be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "jIBWjPsUyNPJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 6s 7ms/step - loss: 0.9182 - accuracy: 0.6499 - val_loss: 0.7940 - val_accuracy: 0.6912\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 4s 7ms/step - loss: 0.7667 - accuracy: 0.7017 - val_loss: 0.7527 - val_accuracy: 0.7048\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 4s 6ms/step - loss: 0.7504 - accuracy: 0.7130 - val_loss: 0.7359 - val_accuracy: 0.7141\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history_2 = model_2.fit(train_dataset,\n",
    "                        steps_per_epoch=int(0.1*len(train_dataset)),\n",
    "                        epochs=3,\n",
    "                        validation_data=valid_dataset,\n",
    "                        validation_steps=int(0.1*len(valid_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we aren't training our own custom embedding layer, training is much quicker.\n",
    "\n",
    "Let's make some predictions and evaluate our feature extraction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "gONQ_ECoyiDA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 5s 5ms/step - loss: 0.7391 - accuracy: 0.7154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7391337156295776, 0.7154442071914673]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on the whole validation dataset\n",
    "model_2.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "twc8hooOyzfT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 5s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.41299683, 0.3739345 , 0.00237512, 0.20311168, 0.00758188],\n",
       "       [0.31789568, 0.54903084, 0.00491524, 0.12524849, 0.00290967],\n",
       "       [0.24129736, 0.15958583, 0.02016221, 0.54049504, 0.03845955],\n",
       "       ...,\n",
       "       [0.00233548, 0.00760787, 0.05840923, 0.00123068, 0.93041676],\n",
       "       [0.00436111, 0.04799273, 0.18456307, 0.00140012, 0.761683  ],\n",
       "       [0.16840817, 0.2606312 , 0.50883335, 0.00725235, 0.05487488]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "model_2_pred_probs = model_2.predict(valid_dataset)\n",
    "model_2_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "zCmsOUzQy9hi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 2], dtype=int64)>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get actual predictions\n",
    "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
    "model_2_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "CMixnbZAzJGY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 71.5444194359857,\n",
       " 'precision': 0.7155878593390147,\n",
       " 'recall': 0.715444194359857,\n",
       " 'f1': 0.7125332970956433}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all evaluation metrics\n",
    "model_2_results = calculate_results(val_labels_encoded, model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "ae28qCtFzcUA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.1832384482987,\n",
       " 'precision': 0.7186466952323352,\n",
       " 'recall': 0.7218323844829869,\n",
       " 'f1': 0.6989250353450294}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqcxDG5_zkUP"
   },
   "source": [
    "### Creating a character-level tokenizer\n",
    "\n",
    "The [*Neural Networks for Joint Sentence Classification\n",
    "in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf) paper mentions their model uses a hybrid of token and character embeddings.\n",
    "\n",
    "We've built models with a custom token embedding and a pretrained token embedding, how about we build one using a character embedding?\n",
    "\n",
    "The difference between a character and token embedding is that the **character embedding** is created using sequences split into characters (e.g. `hello` -> [`h`, `e`, `l`, `l`, `o`]) where as a **token embedding** is created on sequences split into tokens.\n",
    "\n",
    "![example of difference between token level and character level embeddings](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/09-token-vs-character-embeddings.png)\n",
    "*Token level embeddings split sequences into tokens (words) and embeddings each of them, character embeddings split sequences into characters and creates a feature vector for each.*\n",
    "\n",
    "We can create a character-level embedding by first vectorizing our sequences (after they've been split into characters) using the [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) class and then passing those vectorized sequences through an [`Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer.\n",
    "\n",
    "Before we can vectorize our sequences on a character-level we'll need to split them into characters. Let's write a function to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HdbX3_K90yUv",
    "outputId": "791e6d13-ff4f-476f-c294-db7758156fda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
       " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "L86v1jAz02Yf",
    "outputId": "3d937a70-f30f-49ab-839c-48cd9fe97a3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@   ;   @ : @   - @   )   ,   w h i c h   i n v e s t i g a t e d   c l i e n t - t r e a t m e n t   m a t c h i n g   e f f e c t s   f o r   a l c o h o l   t r e a t m e n t   a m o n g   o u t p a t i e n t   (   n   =   @   )   a n d   a f t e r c a r e   (   n   =   @   )   p a r t i c i p a n t s   r a n d o m i z e d   t o   c o g n i t i v e   b e h a v i o r a l   t r e a t m e n t   (   c b t   )   ,   @ - s t e p   f a c i l i t a t i o n   (   t s f   )   ,   o r   m o t i v a t i o n a l   e n h a n c e m e n t   t h e r a p y   (   m e t   )   .'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make function to split sentences into characters\n",
    "def split_chars(text):\n",
    "  return \" \".join(list(text))\n",
    "\n",
    "# Text splitting non-character-level sequence into characters\n",
    "split_chars(random_train_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Looks like our character-splitting function works. Let's create character-level datasets by splitting our sequence datasets into characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_d8XACq1DTu",
    "outputId": "3dad1a9a-3cf2-490e-c914-4f3ab901a84d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .',\n",
       " 'a   t o t a l   o f   @   p a t i e n t s   w i t h   p r i m a r y   k n e e   o a   w e r e   r a n d o m i z e d   @ : @   ;   @   r e c e i v e d   @   m g / d a y   o f   p r e d n i s o l o n e   a n d   @   r e c e i v e d   p l a c e b o   f o r   @   w e e k s   .',\n",
       " 'o u t c o m e   m e a s u r e s   i n c l u d e d   p a i n   r e d u c t i o n   a n d   i m p r o v e m e n t   i n   f u n c t i o n   s c o r e s   a n d   s y s t e m i c   i n f l a m m a t i o n   m a r k e r s   .',\n",
       " 'p a i n   w a s   a s s e s s e d   u s i n g   t h e   v i s u a l   a n a l o g   p a i n   s c a l e   (   @ - @   m m   )   .',\n",
       " 's e c o n d a r y   o u t c o m e   m e a s u r e s   i n c l u d e d   t h e   w e s t e r n   o n t a r i o   a n d   m c m a s t e r   u n i v e r s i t i e s   o s t e o a r t h r i t i s   i n d e x   s c o r e s   ,   p a t i e n t   g l o b a l   a s s e s s m e n t   (   p g a   )   o f   t h e   s e v e r i t y   o f   k n e e   o a   ,   a n d   @ - m i n   w a l k   d i s t a n c e   (   @ m w d   )   .']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split sequence-level data splits into character level data splits\n",
    "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
    "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
    "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
    "\n",
    "train_chars[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To figure out how long our vectorized character sequences should be, let's check the distribution of our character sequence lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PXNYJZf41zdm",
    "outputId": "1094cc3a-f6fb-46ba-a5cb-aabbb28e472a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149.3662574983337"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the average character length?\n",
    "char_length = [len(sentence) for sentence in train_sentences]\n",
    "mean_char_len = np.mean(char_length)\n",
    "mean_char_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "yOVyzTmv2F3t",
    "outputId": "1c9283b9-eabd-4e2b-cf6c-d41f953bbc1e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution of our sequence at a character level\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(char_length, bins=7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, looks like most of our sequences are between 0 and 200 characters long.\n",
    "\n",
    "Let's use NumPy's percentile to figure out what length covers 95% of our sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "llhOwL9G2cau",
    "outputId": "f4ec02fd-bf16-496c-9100-c36d1ae6d89d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find what character length covers 95% of all sequences\n",
    "output_seq_char_len = int(np.percentile(char_length, 95))\n",
    "output_seq_char_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful, now we know the sequence length which covers 95% of sequences, we'll use that in our `TextVectorization` layer as the `output_sequence_length` parameter.\n",
    "\n",
    "> ðŸ”‘ **Note:** You can experiment here to figure out what the optimal `output_sequence_length` should be, perhaps using the mean results in as good results as using the 95% percentile.\n",
    "\n",
    "We'll set `max_tokens` (the total number of different characters in our sequences) to 28, in other words, 26 letters of the alphabet + space + OOV (out of vocabulary or unknown) tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "-iD7tj4NAxJL",
    "outputId": "e423b659-853c-4891-b7f1-793a93db5f36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all keyboard characters\n",
    "import string\n",
    "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "T7tz6zPrBLnT"
   },
   "outputs": [],
   "source": [
    "# Creat char level token vectorizer instance\n",
    "NUM_CHAR_TOKENS = len(alphabet) + 2\n",
    "char_vec = TextVectorization(max_tokens=NUM_CHAR_TOKENS,\n",
    "                             output_sequence_length=output_seq_char_len,\n",
    "                             name='character_vectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "IAHYPW2hCUCQ"
   },
   "outputs": [],
   "source": [
    "# Adapt character vectorizer to training character\n",
    "char_vec.adapt(train_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Now we've adapted our `char_vectorizer` to our character-level sequences, let's check out some characteristics about it using the [`get_vocabulary()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization#get_vocabulary) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WlARFQ5BCpTk",
    "outputId": "e986a3b1-bd07-45c6-ed56-a4a228c77dee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters in vocab: 28\n",
      "Most common characters in vocab: ['', '[UNK]', 'e', 't', 'i']\n",
      "Least common characters in vocab: ['k', 'x', 'z', 'q', 'j']\n"
     ]
    }
   ],
   "source": [
    "# Check character vocab stats\n",
    "char_vocab = char_vec.get_vocabulary()\n",
    "print(f'Number of characters in vocab: {len(char_vocab)}')\n",
    "print(f'Most common characters in vocab: {char_vocab[:5]}')\n",
    "print(f'Least common characters in vocab: {char_vocab[-5:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also test it on random sequences of characters to make sure it's working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5UIA9r2APDZc",
    "outputId": "938b6725-c67c-4d93-e6c6-0a0e35c9aa06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charified text:\n",
      "b o t h   t r e a t m e n t s   i m p r o v e d   a l l   a n k l e   m o v e m e n t s   (   p   <   @   )   .\n",
      "\n",
      "Length of random_train_chars:\n",
      "45\n",
      "\n",
      "Vectorized chars:\n",
      "[[22  7  3 13  3  8  2  5  3 15  2  6  3  9  4 15 14  8  7 21  2 10  5 12\n",
      "  12  5  6 23 12  2 15  7 21  2 15  2  6  3  9 14  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]]\n",
      "\n",
      "Length of vectorized chars:\n",
      "290\n"
     ]
    }
   ],
   "source": [
    "# Test out character vectorizer\n",
    "random_train_chars = random.choice(train_chars)\n",
    "print(f'Charified text:\\n{random_train_chars}\\n')\n",
    "print(f'Length of random_train_chars:\\n{len(random_train_chars.split())}\\n')\n",
    "vectorized_chars = char_vec([random_train_chars])\n",
    "print(f'Vectorized chars:\\n{vectorized_chars}\\n')\n",
    "print(f'Length of vectorized chars:\\n{len(vectorized_chars[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice sequences with a length shorter than 290 (`output_seq_char_length`) get padded with zeros on the end, this ensures all sequences passed to our model are the same length.\n",
    "\n",
    "Also, due to the `standardize` parameter of `TextVectorization` being `\"lower_and_strip_punctuation\"` and the `split` parameter being `\"whitespace\"` by default, symbols (such as `@`) and spaces are removed.\n",
    "\n",
    "> ðŸ”‘ **Note:** If you didn't want punctuation to be removed (keep the `@`, `%` etc), you can create a custom standardization callable and pass it as the `standardize` parameter. See the [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) class documentation for more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l38x4TRxP_vD"
   },
   "source": [
    "### Creating a character-level embedding\n",
    "We've got a way to vectorize our character-level sequences, now's time to create a character-level embedding.\n",
    "\n",
    "Just like our custom token embedding, we can do so using the [`tensorflow.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) class.\n",
    "\n",
    "Our character-level embedding layer requires an input dimension and output dimension. \n",
    "\n",
    "The input dimension (`input_dim`) will be equal to the number of different characters in our `char_vocab` (28). And since we're following the structure of the model in Figure 1 of [*Neural Networks for Joint Sentence Classification\n",
    "in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf), the output dimension of the character embedding (`output_dim`) will be 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "8HVyLgIRQmjj"
   },
   "outputs": [],
   "source": [
    "# Create char level embedding layer\n",
    "char_embed = layers.Embedding(input_dim=len(char_vocab),  # number of different characters\n",
    "                              output_dim=25,  # this is the size of the char embedding in the paper: https://arxiv.org/pdf/1612.05251.pdf (Figure 1)\n",
    "                              mask_zero=True,\n",
    "                              name='char_embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fvM_BW38ROXE",
    "outputId": "ce45914b-9f97-421c-e185-49099f92c6ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character embedding layer:\n",
      "b o t h   t r e a t m e n t s   i m p r o v e d   a l l   a n k l e   m o v e m e n t s   (   p   <   @   )   .\n",
      "\n",
      "Embedded chars. (after vectorization and embedding):\n",
      "[[[-0.0253883   0.02517594  0.01330987 ... -0.04581163  0.03409861\n",
      "    0.00840731]\n",
      "  [ 0.03975358  0.00339144  0.01211687 ...  0.0102856  -0.01192597\n",
      "   -0.02408285]\n",
      "  [-0.00759759 -0.04051381 -0.01768886 ... -0.00744125  0.01600401\n",
      "   -0.00855471]\n",
      "  ...\n",
      "  [ 0.02288398  0.03539277 -0.0048795  ... -0.00273877  0.04466193\n",
      "   -0.03197142]\n",
      "  [ 0.02288398  0.03539277 -0.0048795  ... -0.00273877  0.04466193\n",
      "   -0.03197142]\n",
      "  [ 0.02288398  0.03539277 -0.0048795  ... -0.00273877  0.04466193\n",
      "   -0.03197142]]]\n",
      "\n",
      "Character embeddings shape: (1, 290, 25)\n"
     ]
    }
   ],
   "source": [
    "# Test out character embedding layer\n",
    "print(f'Character embedding layer:\\n{random_train_chars}\\n')\n",
    "char_embed_example = char_embed(char_vec([random_train_chars]))\n",
    "print(f'Embedded chars. (after vectorization and embedding):\\n{char_embed_example}\\n')\n",
    "print(f'Character embeddings shape: {char_embed_example.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful! Each of the characters in our sequences gets turned into a 25 dimension embedding.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klwjREiaRyzc"
   },
   "source": [
    "### Building a Conv1D model to fit on character embeddings\n",
    "Now we've got a way to turn our character-level sequences into numbers (`char_vectorizer`) as well as numerically represent them as an embedding (`char_embed`) let's test how effective they are at encoding the information in our sequences by creating a character-level sequence model.\n",
    "\n",
    "The model will have the same structure as our custom token embedding model (`model_1`) except it'll take character-level sequences as input instead of token-level sequences.\n",
    "\n",
    "```\n",
    "Input (character-level text) -> Tokenize -> Embedding -> Layers (Conv1D, GlobalMaxPool1D) -> Output (label probability)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "id": "hcbIdZTnSZpc"
   },
   "outputs": [],
   "source": [
    "# Make conv1d on chars only\n",
    "inputs = layers.Input(shape=(1,), dtype='string')\n",
    "char_vectors = char_vec(inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "x = layers.Conv1D(64, kernel_size=5, padding='same', activation='relu')(char_embeddings)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(5, activation='softmax')(x)\n",
    "model_3 = tf.keras.Model(inputs,\n",
    "                         outputs,\n",
    "                         name=\"model_3_conv1d_char_embeddings\")\n",
    "\n",
    "# Compile the model\n",
    "model_3.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "MISzSFafTJXj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_conv1d_char_embeddings\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " character_vectorizer (TextV  (None, 290)              0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " char_embed (Embedding)      (None, 290, 25)           700       \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 290, 64)           8064      \n",
      "                                                                 \n",
      " global_average_pooling1d_2   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,089\n",
      "Trainable params: 9,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the summary\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before fitting our model on the data, we'll create char-level batched `PrefetchedDataset`'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "2XJ-DIKkTnFs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create char level datasets\n",
    "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_char_dataset = tf.data.Dataset.from_tensor_slices((test_chars, test_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_char_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like our token-level sequence model, to save time with our experiments, we'll fit the character-level model on 10% of batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "nMveVxjCTSlT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 1.4602 - accuracy: 0.3479 - val_loss: 1.4043 - val_accuracy: 0.4029\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 5s 9ms/step - loss: 1.3661 - accuracy: 0.4228 - val_loss: 1.3346 - val_accuracy: 0.4398\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 5s 9ms/step - loss: 1.3264 - accuracy: 0.4508 - val_loss: 1.3137 - val_accuracy: 0.4481\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history_3 = model_3.fit(train_char_dataset,\n",
    "                        steps_per_epoch=int(0.1*len(train_char_dataset)),\n",
    "                        epochs=3,\n",
    "                        validation_data=val_char_dataset,\n",
    "                        validation_steps=int(0.1*len(val_char_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Looks like our character-level model is working, let's make some predictions with it and evaluate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "7AmwH5zrURVM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 3s 3ms/step - loss: 1.3130 - accuracy: 0.4488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3130031824111938, 0.44876208901405334]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate with full validation dataset\n",
    "model_3.evaluate(val_char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "okPfFscbWzUE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 3s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.17724662, 0.23762478, 0.27706692, 0.17144531, 0.1366164 ],\n",
       "       [0.10742333, 0.16830729, 0.16103032, 0.06267735, 0.5005617 ],\n",
       "       [0.09856822, 0.15282246, 0.4334263 , 0.10798886, 0.20719413],\n",
       "       ...,\n",
       "       [0.0599188 , 0.11062601, 0.23180129, 0.03818654, 0.5594674 ],\n",
       "       [0.04651321, 0.10458387, 0.21877927, 0.04094396, 0.58917964],\n",
       "       [0.13854747, 0.17837383, 0.20746537, 0.0663721 , 0.40924123]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with character model only\n",
    "model_3_pred_probs = model_3.predict(val_char_dataset)\n",
    "model_3_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "-T7VAAg3XAGk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([2, 4, 2, ..., 4, 4, 4], dtype=int64)>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn them into labels\n",
    "model_3_preds = tf.argmax(model_3_pred_probs, axis=1)\n",
    "model_3_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "gu1L5HLjXK2U"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Machine Learning Projects\\skimlit\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 44.87620812922018,\n",
       " 'precision': 0.3768482583077122,\n",
       " 'recall': 0.4487620812922018,\n",
       " 'f1': 0.39235080230251845}"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get model 3 eval metrics\n",
    "model_3_results = calculate_results(val_labels_encoded, model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTVr_857XWy7"
   },
   "source": [
    "## Model 4: Combining pretrained token embeddings + character embeddings (hybrid embedding layer)\n",
    "\n",
    "Alright, now things are going to get spicy.\n",
    "\n",
    "In moving closer to build a model similar to the one in Figure 1 of [*Neural Networks for Joint Sentence Classification\n",
    "in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf), it's time we tackled the hybrid token embedding layer they speak of.\n",
    "\n",
    "This hybrid token embedding layer is a combination of token embeddings and character embeddings. In other words, they create a stacked embedding to represent sequences before passing them to the sequence label prediction layer.\n",
    "\n",
    "So far we've built two models which have used token and character-level embeddings, however, these two models have used each of these embeddings exclusively.\n",
    "\n",
    "To start replicating (or getting close to replicating) the model in Figure 1, we're going to go through the following steps:\n",
    "1. Create a token-level model (similar to `model_1`)\n",
    "2. Create a character-level model (similar to `model_3` with a slight modification to reflect the paper)\n",
    "3. Combine (using [`layers.Concatenate`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate)) the outputs of 1 and 2\n",
    "4. Build a series of output layers on top of 3 similar to Figure 1 and section 4.2 of [*Neural Networks for Joint Sentence Classification\n",
    "in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf)\n",
    "5. Construct a model which takes token and character-level sequences as input and produces sequence label probabilities as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "id": "3kjYvYctdm3u"
   },
   "outputs": [],
   "source": [
    "# 1. Setup token inputs/Model\n",
    "token_inputs = layers.Input(shape=[], dtype=tf.string, name='token_input')\n",
    "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
    "token_output = layers.Dense(128, activation='relu')(token_embeddings)\n",
    "token_model = tf.keras.Model(inputs=token_inputs,\n",
    "                             outputs=token_output)\n",
    "\n",
    "# 2. Setup char inputs/Model\n",
    "char_inputs = layers.Input(shape=(1, ), dtype=tf.string, name=\"char_input\")\n",
    "char_vectors = char_vec(char_inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "char_bi_lstm = layers.Bidirectional(layers.LSTM(24))(char_embeddings)\n",
    "char_model = tf.keras.Model(inputs=char_inputs,\n",
    "                            outputs=char_bi_lstm)\n",
    "\n",
    "# 3. Combine token and char embeddings (create hybrid token embedding)\n",
    "token_char_concat = layers.Concatenate(name='token_char_hybrid')([token_model.output,\n",
    "                                                                  char_model.output])\n",
    "\n",
    "# 4. Create output layers - adding in Dropout\n",
    "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
    "combined_dense = layers.Dense(128, activation='relu')(combined_dropout)\n",
    "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
    "output_layer = layers.Dense(5, activation='softmax')(final_dropout)\n",
    "\n",
    "# 5. Construct model with char and token inputs\n",
    "model_4 = tf.keras.Model(inputs=[token_model.input, char_model.input],\n",
    "                         outputs=output_layer,\n",
    "                         name='model_4_token_and_char_embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah... There's a lot going on here, let's get a summary and plot our model to visualize what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "id": "w0OMEq5ceVH1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_token_and_char_embeddings\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " char_input (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " token_input (InputLayer)       [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " character_vectorizer (TextVect  (None, 290)         0           ['char_input[0][0]']             \n",
      " orization)                                                                                       \n",
      "                                                                                                  \n",
      " universal_sentence_encoder (Ke  (None, 512)         256797824   ['token_input[0][0]']            \n",
      " rasLayer)                                                                                        \n",
      "                                                                                                  \n",
      " char_embed (Embedding)         (None, 290, 25)      700         ['character_vectorizer[1][0]']   \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 128)          65664       ['universal_sentence_encoder[1][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 48)          9600        ['char_embed[1][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " token_char_hybrid (Concatenate  (None, 176)         0           ['dense_9[0][0]',                \n",
      " )                                                                'bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 176)          0           ['token_char_hybrid[0][0]']      \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 128)          22656       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 128)          0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 5)            645         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 256,897,089\n",
      "Trainable params: 99,265\n",
      "Non-trainable params: 256,797,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary of our model\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "id": "0mxaRhGqvQts"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# Plot hybrid token and character model\n",
    "from keras.utils import plot_model\n",
    "plot_model(model_4, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that's a good looking model. Let's compile it just as we have the rest of our models.\n",
    "\n",
    "> ðŸ”‘ **Note:** Section 4.2 of [*Neural Networks for Joint Sentence Classification\n",
    "in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf) mentions using the SGD (stochastic gradient descent) optimizer, however, to stay consistent with our other models, we're going to use the Adam optimizer. As an exercise, you could try using [`tf.keras.optimizers.SGD`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) instead of [`tf.keras.optimizers.Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "tZyJYVgLvfqs"
   },
   "outputs": [],
   "source": [
    "# Compile token char model\n",
    "model_4.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCSg8LqDwPWB"
   },
   "source": [
    "And again, to keep our experiments fast, we'll fit our token-character-hybrid model on 10% of training and validate on 10% of validation batches. However, the difference with this model is that it requires two inputs, token-level sequences and character-level sequences.\n",
    "\n",
    "We can do this by create a `tf.data.Dataset` with a tuple as it's first input, for example:\n",
    "* `((token_data, char_data), (label))`\n",
    "\n",
    "Let's see it in action.\n",
    "\n",
    "### Combining token and character data into a `tf.data` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "AJhbFJQixJN5"
   },
   "outputs": [],
   "source": [
    "# Combine chars and tokens into a dataset\n",
    "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars))\n",
    "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot)\n",
    "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels))\n",
    "\n",
    "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))\n",
    "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
    "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
    "\n",
    "test_char_token_data = tf.data.Dataset.from_tensor_slices((test_sentences, test_chars))\n",
    "test_char_token_labels = tf.data.Dataset.from_tensor_slices(test_labels_one_hot)\n",
    "test_char_token_dataset = tf.data.Dataset.zip((test_char_token_data, test_char_token_labels))\n",
    "\n",
    "\n",
    "# Prefetch and batch train data\n",
    "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_char_token_dataset = test_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a model on token and character-level sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "XBYsm5F8yhEb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 69s 110ms/step - loss: 0.9852 - accuracy: 0.6043 - val_loss: 0.7961 - val_accuracy: 0.6915\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 60s 106ms/step - loss: 0.8100 - accuracy: 0.6862 - val_loss: 0.7305 - val_accuracy: 0.7194\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 59s 105ms/step - loss: 0.7844 - accuracy: 0.7007 - val_loss: 0.7033 - val_accuracy: 0.7264\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history_4 = model_4.fit(train_char_token_dataset,\n",
    "            steps_per_epoch=int(0.1*len(train_char_token_dataset)),\n",
    "            epochs=3,\n",
    "            validation_data=val_char_token_dataset,\n",
    "            validation_steps=int(0.1*len(val_char_token_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "nK8_zWOTy2ts"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 21s 22ms/step - loss: 0.7064 - accuracy: 0.7280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7063537240028381, 0.7279557585716248]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on whole validation dataset\n",
    "model_4.evaluate(val_char_token_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Our token-character hybrid model has come to life!\n",
    "\n",
    "To make predictions with it, since it takes multiplie inputs, we can pass the `predict()` method a tuple of token-level sequences and character-level sequences.\n",
    "\n",
    "We can then evaluate the predictions as we've done before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "nKee4CfB3yG_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 23s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.0430796e-01, 4.0007895e-01, 5.9660538e-03, 1.8085632e-01,\n",
       "        8.7907249e-03],\n",
       "       [3.5456145e-01, 4.6395561e-01, 2.9248423e-03, 1.7712876e-01,\n",
       "        1.4292569e-03],\n",
       "       [2.8191757e-01, 1.7461224e-01, 4.8636049e-02, 4.6615359e-01,\n",
       "        2.8680557e-02],\n",
       "       ...,\n",
       "       [5.0192216e-04, 7.5562750e-03, 5.4275677e-02, 3.0154848e-04,\n",
       "        9.3736458e-01],\n",
       "       [4.5766770e-03, 5.2180618e-02, 2.1603575e-01, 2.3593903e-03,\n",
       "        7.2484750e-01],\n",
       "       [2.2720607e-01, 3.8947296e-01, 2.9584807e-01, 2.5728853e-02,\n",
       "        6.1744064e-02]], dtype=float32)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions\n",
    "model_4_pred_probs = model_4.predict(val_char_token_dataset)\n",
    "model_4_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "N-_pLNoM4BM0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 1], dtype=int64)>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn those predictions into labels\n",
    "model_4_preds = tf.argmax(model_4_pred_probs, axis=1)\n",
    "model_4_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "t4Cz1lAe4JCk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.79557791605984,\n",
       " 'precision': 0.7307841312001448,\n",
       " 'recall': 0.7279557791605984,\n",
       " 'f1': 0.723641494719868}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate various metrics of model\n",
    "model_4_results = calculate_results(val_labels_encoded, model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "id": "KRJA8JSq4f63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.1832384482987,\n",
       " 'precision': 0.7186466952323352,\n",
       " 'recall': 0.7218323844829869,\n",
       " 'f1': 0.6989250353450294}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oJMHjz-5Jsj"
   },
   "source": [
    "## Model 5: Transfer Learning with pretrained token embeddings + character embeddings + positional embeddings \n",
    "\n",
    "It seems like combining token embeddings and character embeddings gave our model a little performance boost.\n",
    "\n",
    "But there's one more piece of the puzzle we can add in.\n",
    "\n",
    "What if we engineered our own features into the model?\n",
    "\n",
    "Meaning, what if we took our own knowledge about the data and encoded it in a numerical way to give our model more information about our samples?\n",
    "\n",
    "The process of applying your own knowledge to build features as input to a model is called **feature engineering**.\n",
    "\n",
    "Can you think of something important about the sequences we're trying to classify?\n",
    "\n",
    "If you were to look at an abstract, would you expect the sentences to appear in order? Or does it make sense if they were to appear sequentially? For example, sequences labelled `CONCLUSIONS` at the beggining and sequences labelled `OBJECTIVE` at the end?\n",
    "\n",
    "Abstracts typically come in a sequential order, such as:\n",
    "* `OBJECTIVE` ...\n",
    "* `METHODS` ...\n",
    "* `METHODS` ...\n",
    "* `METHODS` ...\n",
    "* `RESULTS` ...\n",
    "* `CONCLUSIONS` ...\n",
    "\n",
    "Or\n",
    "\n",
    "* `BACKGROUND` ...\n",
    "* `OBJECTIVE` ...\n",
    "* `METHODS` ...\n",
    "* `METHODS` ...\n",
    "* `RESULTS` ...\n",
    "* `RESULTS` ...\n",
    "* `CONCLUSIONS` ...\n",
    "* `CONCLUSIONS` ...\n",
    "\n",
    "Of course, we can't engineer the sequence labels themselves into the training data (we don't have these at test time), but we can encode the order of a set of sequences in an abstract.\n",
    "\n",
    "For example,\n",
    "* `Sentence 1 of 10` ...\n",
    "* `Sentence 2 of 10` ...\n",
    "* `Sentence 3 of 10` ...\n",
    "* `Sentence 4 of 10` ...\n",
    "* ...\n",
    "\n",
    "\n",
    "You might've noticed this when we created our `preprocess_text_with_line_numbers()` function. When we read in a text file of abstracts, we counted the number of lines in an abstract as well as the number of each line itself.\n",
    "\n",
    "Doing this led to the `\"line_number\"` and `\"total_lines\"` columns of our DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "id": "qmo2eYZ6GUlw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>a total of @ patients with primary knee oa wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>pain was assessed using the visual analog pain...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>secondary outcome measures included the wester...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target                                               text  line_number  \\\n",
       "0  OBJECTIVE  to investigate the efficacy of @ weeks of dail...            0   \n",
       "1    METHODS  a total of @ patients with primary knee oa wer...            1   \n",
       "2    METHODS  outcome measures included pain reduction and i...            2   \n",
       "3    METHODS  pain was assessed using the visual analog pain...            3   \n",
       "4    METHODS  secondary outcome measures included the wester...            4   \n",
       "\n",
       "   total_lines  \n",
       "0           11  \n",
       "1           11  \n",
       "2           11  \n",
       "3           11  \n",
       "4           11  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `\"line_number\"` and `\"total_lines\"` columns are features which didn't necessarily come with the training data but can be passed to our model as a **positional embedding**. In other words, the positional embedding is where the sentence appears in an abstract.\n",
    "\n",
    "We can use these features because they will be available at test time. \n",
    "\n",
    "![example of engineering features into our dataset to help our model](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/09-engineered-features-at-test-time.png)\n",
    "*Since abstracts typically have a sequential order about them (for example, background, objective, methods, results, conclusion), it makes sense to add the line number of where a particular sentence occurs to our model. The beautiful thing is, these features will be available at test time (we can just count the number of sentences in an abstract and the number of each one).*\n",
    "\n",
    "Meaning, if we were to predict the labels of sequences in an abstract our model had never seen, we could count the number of lines and the track the position of each individual line and pass it to our model.\n",
    "\n",
    "> ðŸ›  **Exercise:** Another way of creating our positional embedding feature would be to combine the `\"line_number\"` and `\"total_lines\"` columns into one, for example a `\"line_position\"` column may contain values like `1_of_11`, `2_of_11`, etc. Where `1_of_11` would be the first line in an abstract 11 sentences long. After going through the following steps, you might want to revisit this positional embedding stage and see how a combined column of `\"line_position\"` goes against two separate columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTmSFm3JGWBd"
   },
   "source": [
    "\n",
    "### Create positional embeddings\n",
    "\n",
    "Okay, enough talk about positional embeddings, let's create them.\n",
    "\n",
    "Since our `\"line_number\"` and `\"total_line\"` columns are already numerical, we could pass them as they are to our model.\n",
    "\n",
    "But to avoid our model thinking a line with `\"line_number\"=5` is five times greater than a line with `\"line_number\"=1`, we'll use one-hot-encoding to encode our `\"line_number\"` and `\"total_lines\"` features.\n",
    "\n",
    "To do this, we can use the [`tf.one_hot`](https://www.tensorflow.org/api_docs/python/tf/one_hot) utility.\n",
    "\n",
    "`tf.one_hot` returns a one-hot-encoded tensor. It accepts an array (or tensor) as input and the `depth` parameter determines the dimension of the returned tensor.\n",
    "\n",
    "To figure out what we should set the `depth` parameter to, let's investigate the distribution of the `\"line_number\"` column.\n",
    "\n",
    "> ðŸ”‘ **Note 1:** When it comes to one-hot-encoding our features, Scikit-Learn's [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) class is another viable option here.\n",
    "\n",
    "> ðŸ”‘ **Note 2:** Any engineered features used to train a model need to available at test time. In our case, line numbers and total lines are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TO7dQkdHcdO"
   },
   "source": [
    "### Create positional embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2pDkIedHhH6",
    "outputId": "c1b20c49-0967-4ef7-e16f-84b68c949134"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     15000\n",
       "1     15000\n",
       "2     15000\n",
       "3     15000\n",
       "4     14992\n",
       "5     14949\n",
       "6     14758\n",
       "7     14279\n",
       "8     13346\n",
       "9     11981\n",
       "10    10041\n",
       "11     7892\n",
       "12     5853\n",
       "13     4152\n",
       "14     2835\n",
       "15     1861\n",
       "16     1188\n",
       "17      751\n",
       "18      462\n",
       "19      286\n",
       "20      162\n",
       "21      101\n",
       "22       66\n",
       "23       33\n",
       "24       22\n",
       "25       14\n",
       "26        7\n",
       "27        4\n",
       "28        3\n",
       "29        1\n",
       "30        1\n",
       "Name: line_number, dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many different line numbers are there?\n",
    "train_df.line_number.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "3_SXhjnvHr5q",
    "outputId": "0d67a970-6902-4554-c3e5-f5713a16a596"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAGdCAYAAAAPLEfqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqEElEQVR4nO3dfXAUdZ7H8U8emPCUCQZIQo5AsoJglqciQJjz4RbJMki0RLAKFCVi1MMNHBCRhz0XxLU2CCWCB8huuRKtE0H2xF3JAbIBwnlGkGDkoZaILG7gwoSokIFoHsj0/eFmljGoP8ZgD+H9qpoqpvubns90tZWPPT2dMMuyLAEAAOA7hdsdAAAA4GpAaQIAADBAaQIAADBAaQIAADBAaQIAADBAaQIAADBAaQIAADBAaQIAADAQaXeA1sLn86miokLR0dEKCwuzOw4AADBgWZbOnTunxMREhYd/97kkSlMLqaioUFJSkt0xAABAEE6cOKHu3bt/5wylqYVER0dL+nqnO51Om9MAAAATXq9XSUlJ/t/j34XS1EKaPpJzOp2UJgAArjIml9ZwITgAAIABShMAAIABShMAAIABShMAAIABShMAAIABShMAAIABShMAAIABShMAAIABShMAAIABShMAAIABShMAAIABShMAAIABShMAAIABShMAAICBSLsDwEzyvAK7I1y2Txdn2h0BAIAWQ2nCFUPRAwC0Jnw8BwAAYIDSBAAAYIDSBAAAYIDSBAAAYIDSBAAAYIDSBAAAYIDSBAAAYIDSBAAAYIDSBAAAYIDSBAAAYIDSBAAAYIDSBAAAYIDSBAAAYIDSBAAAYIDSBAAAYIDSBAAAYIDSBAAAYIDSBAAAYIDSBAAAYCDS7gBAKEmeV2B3hMv26eJMuyMAwDWBM00AAAAGKE0AAAAGKE0AAAAGKE0AAAAGKE0AAAAGKE0AAAAGKE0AAAAGKE0AAAAGKE0AAAAGKE0AAAAGKE0AAAAGKE0AAAAGKE0AAAAGQqY0LV68WGFhYZo5c6Z/WW1trXJyctS5c2d17NhR48ePV2VlZcDPlZeXKzMzU+3bt1dcXJyeeOIJXbhwIWBm165dGjx4sKKiotSrVy/l5+c3e/1Vq1YpOTlZbdu2VXp6uvbu3Xsl3iYAALhKhURp+uCDD/Tb3/5WAwYMCFg+a9Ysvf3229q4caOKiopUUVGhcePG+dc3NjYqMzNT9fX1eu+99/TKK68oPz9fCxYs8M8cP35cmZmZGjFihEpLSzVz5kw9/PDD2rZtm39mw4YNys3N1cKFC7V//34NHDhQbrdbp0+fvvJvHgAAXBXCLMuy7Axw/vx5DR48WKtXr9YzzzyjQYMGafny5aqurlbXrl21bt063XPPPZKkI0eO6MYbb1RxcbGGDx+uLVu26I477lBFRYXi4+MlSWvWrNHcuXNVVVUlh8OhuXPnqqCgQIcOHfK/5sSJE3X27Flt3bpVkpSenq6hQ4dq5cqVkiSfz6ekpCRNnz5d8+bNM3ofXq9XMTExqq6ultPpbMldJElKnlfQ4ttE6/Dp4ky7IwDAVetyfn/bfqYpJydHmZmZysjICFheUlKihoaGgOV9+/ZVjx49VFxcLEkqLi5W//79/YVJktxut7xerw4fPuyf+ea23W63fxv19fUqKSkJmAkPD1dGRoZ/5lLq6urk9XoDHgAAoPWKtPPF169fr/379+uDDz5ots7j8cjhcKhTp04By+Pj4+XxePwzFxempvVN675rxuv16quvvtKZM2fU2Nh4yZkjR458a/a8vDwtWrTI7I0CAICrnm1nmk6cOKEZM2botddeU9u2be2KEbT58+erurra/zhx4oTdkQAAwBVkW2kqKSnR6dOnNXjwYEVGRioyMlJFRUV64YUXFBkZqfj4eNXX1+vs2bMBP1dZWamEhARJUkJCQrNv0zU9/74Zp9Opdu3aqUuXLoqIiLjkTNM2LiUqKkpOpzPgAQAAWi/bStPIkSN18OBBlZaW+h9DhgzRpEmT/P9u06aNCgsL/T9TVlam8vJyuVwuSZLL5dLBgwcDvuW2fft2OZ1Opaam+mcu3kbTTNM2HA6H0tLSAmZ8Pp8KCwv9MwAAALZd0xQdHa1+/foFLOvQoYM6d+7sX56dna3c3FzFxsbK6XRq+vTpcrlcGj58uCRp1KhRSk1N1QMPPKAlS5bI4/HoySefVE5OjqKioiRJU6dO1cqVKzVnzhw99NBD2rFjh9544w0VFPzj22i5ubnKysrSkCFDNGzYMC1fvlw1NTWaMmXKj7Q3AABAqLP1QvDv8/zzzys8PFzjx49XXV2d3G63Vq9e7V8fERGhzZs367HHHpPL5VKHDh2UlZWlp59+2j+TkpKigoICzZo1SytWrFD37t310ksvye12+2cmTJigqqoqLViwQB6PR4MGDdLWrVubXRwOAACuXbbfp6m14D5NsAv3aQKA4F1V92kCAAC4GlCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADFCaAAAADNhaml588UUNGDBATqdTTqdTLpdLW7Zs8a+vra1VTk6OOnfurI4dO2r8+PGqrKwM2EZ5ebkyMzPVvn17xcXF6YknntCFCxcCZnbt2qXBgwcrKipKvXr1Un5+frMsq1atUnJystq2bav09HTt3bv3irxnAABwdbK1NHXv3l2LFy9WSUmJ9u3bp9tuu0133XWXDh8+LEmaNWuW3n77bW3cuFFFRUWqqKjQuHHj/D/f2NiozMxM1dfX67333tMrr7yi/Px8LViwwD9z/PhxZWZmasSIESotLdXMmTP18MMPa9u2bf6ZDRs2KDc3VwsXLtT+/fs1cOBAud1unT59+sfbGQAAIKSFWZZl2R3iYrGxsVq6dKnuuecede3aVevWrdM999wjSTpy5IhuvPFGFRcXa/jw4dqyZYvuuOMOVVRUKD4+XpK0Zs0azZ07V1VVVXI4HJo7d64KCgp06NAh/2tMnDhRZ8+e1datWyVJ6enpGjp0qFauXClJ8vl8SkpK0vTp0zVv3jyj3F6vVzExMaqurpbT6WzJXSJJSp5X0OLbROvw6eJMuyMAwFXrcn5/h8w1TY2NjVq/fr1qamrkcrlUUlKihoYGZWRk+Gf69u2rHj16qLi4WJJUXFys/v37+wuTJLndbnm9Xv/ZquLi4oBtNM00baO+vl4lJSUBM+Hh4crIyPDPAAAARNod4ODBg3K5XKqtrVXHjh21adMmpaamqrS0VA6HQ506dQqYj4+Pl8fjkSR5PJ6AwtS0vmndd814vV599dVXOnPmjBobGy85c+TIkW/NXVdXp7q6Ov9zr9d7eW8cAABcVWwvTX369FFpaamqq6v1hz/8QVlZWSoqKrI71vfKy8vTokWL7I4BXJUf3fKRIoCrke0fzzkcDvXq1UtpaWnKy8vTwIEDtWLFCiUkJKi+vl5nz54NmK+srFRCQoIkKSEhodm36Zqef9+M0+lUu3bt1KVLF0VERFxypmkblzJ//nxVV1f7HydOnAjq/QMAgKuD7aXpm3w+n+rq6pSWlqY2bdqosLDQv66srEzl5eVyuVySJJfLpYMHDwZ8y2379u1yOp1KTU31z1y8jaaZpm04HA6lpaUFzPh8PhUWFvpnLiUqKsp/q4SmBwAAaL1s/Xhu/vz5uv3229WjRw+dO3dO69at065du7Rt2zbFxMQoOztbubm5io2NldPp1PTp0+VyuTR8+HBJ0qhRo5SamqoHHnhAS5Yskcfj0ZNPPqmcnBxFRUVJkqZOnaqVK1dqzpw5euihh7Rjxw698cYbKij4x0caubm5ysrK0pAhQzRs2DAtX75cNTU1mjJlii37BQAAhB5bS9Pp06c1efJknTp1SjExMRowYIC2bdumn//855Kk559/XuHh4Ro/frzq6urkdru1evVq/89HRERo8+bNeuyxx+RyudShQwdlZWXp6aef9s+kpKSooKBAs2bN0ooVK9S9e3e99NJLcrvd/pkJEyaoqqpKCxYskMfj0aBBg7R169ZmF4cDAIBrV8jdp+lqxX2aAHNcCA4gVFyV92kCAAAIZZQmAAAAA5QmAAAAA5QmAAAAA5QmAAAAA5QmAAAAA5QmAAAAA5QmAAAAA5QmAAAAA5QmAAAAA5QmAAAAA0GVpr/+9a8tnQMAACCkBVWaevXqpREjRug///M/VVtb29KZAAAAQk5QpWn//v0aMGCAcnNzlZCQoH/913/V3r17WzobAABAyAiqNA0aNEgrVqxQRUWFXn75ZZ06dUo333yz+vXrp2XLlqmqqqqlcwIAANjqB10IHhkZqXHjxmnjxo169tln9cknn2j27NlKSkrS5MmTderUqZbKCQAAYKsfVJr27dunX/ziF+rWrZuWLVum2bNn69ixY9q+fbsqKip01113tVROAAAAW0UG80PLli3T2rVrVVZWpjFjxujVV1/VmDFjFB7+dQdLSUlRfn6+kpOTWzIrAACAbYIqTS+++KIeeughPfjgg+rWrdslZ+Li4vT73//+B4UDAAAIFUGVpqNHj37vjMPhUFZWVjCbBwAACDlBXdO0du1abdy4sdnyjRs36pVXXvnBoQAAAEJNUKUpLy9PXbp0abY8Li5Ov/nNb35wKAAAgFATVGkqLy9XSkpKs+U9e/ZUeXn5Dw4FAAAQaoIqTXFxcTpw4ECz5R999JE6d+78g0MBAACEmqBK07333qt/+7d/086dO9XY2KjGxkbt2LFDM2bM0MSJE1s6IwAAgO2C+vbcr3/9a3366acaOXKkIiO/3oTP59PkyZO5pgkAALRKQZUmh8OhDRs26Ne//rU++ugjtWvXTv3791fPnj1bOh8AAEBICKo0Nbnhhht0ww03tFQWAACAkBVUaWpsbFR+fr4KCwt1+vRp+Xy+gPU7duxokXAAAAChIqjSNGPGDOXn5yszM1P9+vVTWFhYS+cCAAAIKUGVpvXr1+uNN97QmDFjWjoPAABASArqlgMOh0O9evVq6SwAAAAhK6jS9Pjjj2vFihWyLKul8wAAAISkoD6ee/fdd7Vz505t2bJFP/3pT9WmTZuA9W+++WaLhAMAAAgVQZWmTp066e67727pLAAAACErqNK0du3als4BAAAQ0oK6pkmSLly4oD//+c/67W9/q3PnzkmSKioqdP78+RYLBwAAECqCOtP0t7/9TaNHj1Z5ebnq6ur085//XNHR0Xr22WdVV1enNWvWtHROAAAAWwV1pmnGjBkaMmSIzpw5o3bt2vmX33333SosLGyxcAAAAKEiqDNN//M//6P33ntPDocjYHlycrL+7//+r0WCAQAAhJKgzjT5fD41NjY2W37y5ElFR0f/4FAAAAChJqjSNGrUKC1fvtz/PCwsTOfPn9fChQv50yoAAKBVCurjueeee05ut1upqamqra3Vfffdp6NHj6pLly56/fXXWzojAACA7YIqTd27d9dHH32k9evX68CBAzp//ryys7M1adKkgAvDAQAAWougSpMkRUZG6v7772/JLAAAACErqNL06quvfuf6yZMnBxUGAAAgVAVVmmbMmBHwvKGhQV9++aUcDofat29PaQIAAK1OUN+eO3PmTMDj/PnzKisr080338yF4AAAoFUK+m/PfVPv3r21ePHiZmehAAAAWoMWK03S1xeHV1RUtOQmAQAAQkJQ1zT96U9/CnhuWZZOnTqllStX6qabbmqRYAAAAKEkqNI0duzYgOdhYWHq2rWrbrvtNj333HMtkQsAACCkBFWafD5fS+cAAAAIaS16TRMAAEBrFdSZptzcXOPZZcuWBfMSAAAAISWo0vThhx/qww8/VENDg/r06SNJ+vjjjxUREaHBgwf758LCwlomJQAAgM2CKk133nmnoqOj9corr+i6666T9PUNL6dMmaJbbrlFjz/+eIuGBAAAsFtQ1zQ999xzysvL8xcmSbruuuv0zDPP8O05AADQKgVVmrxer6qqqpotr6qq0rlz535wKAAAgFATVGm6++67NWXKFL355ps6efKkTp48qf/6r/9Sdna2xo0b19IZAQAAbBfUNU1r1qzR7Nmzdd9996mhoeHrDUVGKjs7W0uXLm3RgAAAAKEgqNLUvn17rV69WkuXLtWxY8ckSddff706dOjQouEAAABCxQ+6ueWpU6d06tQp9e7dWx06dJBlWS2VCwAAIKQEVZo+//xzjRw5UjfccIPGjBmjU6dOSZKys7O53QAAAGiVgipNs2bNUps2bVReXq727dv7l0+YMEFbt25tsXAAAAChIqhrmt555x1t27ZN3bt3D1jeu3dv/e1vf2uRYAAAAKEkqDNNNTU1AWeYmnzxxReKior6waEAAABCTVCl6ZZbbtGrr77qfx4WFiafz6clS5ZoxIgRLRYOAAAgVARVmpYsWaLf/e53uv3221VfX685c+aoX79+2r17t5599lnj7eTl5Wno0KGKjo5WXFycxo4dq7KysoCZ2tpa5eTkqHPnzurYsaPGjx+vysrKgJny8nJlZmaqffv2iouL0xNPPKELFy4EzOzatUuDBw9WVFSUevXqpfz8/GZ5Vq1apeTkZLVt21bp6enau3ev+U4BAACtWlClqV+/fvr44491880366677lJNTY3GjRunDz/8UNdff73xdoqKipSTk6P3339f27dvV0NDg0aNGqWamhr/zKxZs/T2229r48aNKioqUkVFRcBdxxsbG5WZman6+nq99957euWVV5Sfn68FCxb4Z44fP67MzEyNGDFCpaWlmjlzph5++GFt27bNP7Nhwwbl5uZq4cKF2r9/vwYOHCi3263Tp08Hs4sAAEArE2Zd5s2VGhoaNHr0aK1Zs0a9e/du0TBVVVWKi4tTUVGRbr31VlVXV6tr165at26d7rnnHknSkSNHdOONN6q4uFjDhw/Xli1bdMcdd6iiokLx8fGSvr5j+dy5c1VVVSWHw6G5c+eqoKBAhw4d8r/WxIkTdfbsWf+3/dLT0zV06FCtXLlSkuTz+ZSUlKTp06dr3rx535vd6/UqJiZG1dXVcjqdLbpfJCl5XkGLbxOwy6eLM+2OAACSLu/392WfaWrTpo0OHDgQdLjvUl1dLUmKjY2VJJWUlKihoUEZGRn+mb59+6pHjx4qLi6WJBUXF6t///7+wiRJbrdbXq9Xhw8f9s9cvI2mmaZt1NfXq6SkJGAmPDxcGRkZ/plvqqurk9frDXgAAIDWK6iP5+6//379/ve/b9EgPp9PM2fO1E033aR+/fpJkjwejxwOhzp16hQwGx8fL4/H45+5uDA1rW9a910zXq9XX331lT777DM1NjZecqZpG9+Ul5enmJgY/yMpKSm4Nw4AAK4KQd2n6cKFC3r55Zf15z//WWlpac3+5tyyZcsue5s5OTk6dOiQ3n333WAi/ejmz5+v3Nxc/3Ov10txAgCgFbus0vTXv/5VycnJOnTokAYPHixJ+vjjjwNmwsLCLjvEtGnTtHnzZu3evTvghpkJCQmqr6/X2bNnA842VVZWKiEhwT/zzW+5NX277uKZb37jrrKyUk6nU+3atVNERIQiIiIuOdO0jW+KiorinlQAAFxDLuvjud69e+uzzz7Tzp07tXPnTsXFxWn9+vX+5zt37tSOHTuMt2dZlqZNm6ZNmzZpx44dSklJCViflpamNm3aqLCw0L+srKxM5eXlcrlckiSXy6WDBw8GfMtt+/btcjqdSk1N9c9cvI2mmaZtOBwOpaWlBcz4fD4VFhb6ZwAAwLXtss40ffOLdlu2bAm4PcDlysnJ0bp16/THP/5R0dHR/uuHYmJi1K5dO8XExCg7O1u5ubmKjY2V0+nU9OnT5XK5NHz4cEnSqFGjlJqaqgceeEBLliyRx+PRk08+qZycHP+ZoKlTp2rlypWaM2eOHnroIe3YsUNvvPGGCgr+8Y203NxcZWVlaciQIRo2bJiWL1+umpoaTZkyJej3BwAAWo+grmlqcpl3K2jmxRdflCT97Gc/C1i+du1aPfjgg5Kk559/XuHh4Ro/frzq6urkdru1evVq/2xERIQ2b96sxx57TC6XSx06dFBWVpaefvpp/0xKSooKCgo0a9YsrVixQt27d9dLL70kt9vtn5kwYYKqqqq0YMECeTweDRo0SFu3bm12cTgAALg2XdZ9miIiIuTxeNS1a1dJUnR0tA4cONDsY7VrEfdpAsxxnyYAoeJyfn9f9sdzDz74oP9jr9raWk2dOrXZt+fefPPNy4wMAAAQ2i6rNGVlZQU8v//++1s0DAAAQKi6rNK0du3aK5UDAAAgpAV1R3AAAIBrDaUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAAKUJAADAQKTdAQBce5LnFdgd4bJ9ujjT7ggAbMaZJgAAAAOUJgAAAAOUJgAAAAOUJgAAAAOUJgAAAAOUJgAAAAOUJgAAAAOUJgAAAAOUJgAAAAOUJgAAAAOUJgAAAAOUJgAAAAOUJgAAAAOUJgAAAAOUJgAAAAOUJgAAAAOUJgAAAAO2lqbdu3frzjvvVGJiosLCwvTWW28FrLcsSwsWLFC3bt3Url07ZWRk6OjRowEzX3zxhSZNmiSn06lOnTopOztb58+fD5g5cOCAbrnlFrVt21ZJSUlasmRJsywbN25U37591bZtW/Xv31///d//3eLvFwAAXL1sLU01NTUaOHCgVq1adcn1S5Ys0QsvvKA1a9Zoz5496tChg9xut2pra/0zkyZN0uHDh7V9+3Zt3rxZu3fv1qOPPupf7/V6NWrUKPXs2VMlJSVaunSpnnrqKf3ud7/zz7z33nu69957lZ2drQ8//FBjx47V2LFjdejQoSv35gEAwFUlzLIsy+4QkhQWFqZNmzZp7Nixkr4+y5SYmKjHH39cs2fPliRVV1crPj5e+fn5mjhxov7yl78oNTVVH3zwgYYMGSJJ2rp1q8aMGaOTJ08qMTFRL774ov793/9dHo9HDodDkjRv3jy99dZbOnLkiCRpwoQJqqmp0ebNm/15hg8frkGDBmnNmjVG+b1er2JiYlRdXS2n09lSu8UveV5Bi28TgLlPF2faHQHAFXA5v79D9pqm48ePy+PxKCMjw78sJiZG6enpKi4uliQVFxerU6dO/sIkSRkZGQoPD9eePXv8M7feequ/MEmS2+1WWVmZzpw545+5+HWaZppe51Lq6urk9XoDHgAAoPUK2dLk8XgkSfHx8QHL4+Pj/es8Ho/i4uIC1kdGRio2NjZg5lLbuPg1vm2maf2l5OXlKSYmxv9ISkq63LcIAACuIiFbmkLd/PnzVV1d7X+cOHHC7kgAAOAKCtnSlJCQIEmqrKwMWF5ZWelfl5CQoNOnTwesv3Dhgr744ouAmUtt4+LX+LaZpvWXEhUVJafTGfAAAACtV8iWppSUFCUkJKiwsNC/zOv1as+ePXK5XJIkl8uls2fPqqSkxD+zY8cO+Xw+paen+2d2796thoYG/8z27dvVp08fXXfddf6Zi1+naabpdQAAAGwtTefPn1dpaalKS0slfX3xd2lpqcrLyxUWFqaZM2fqmWee0Z/+9CcdPHhQkydPVmJiov8bdjfeeKNGjx6tRx55RHv37tX//u//atq0aZo4caISExMlSffdd58cDoeys7N1+PBhbdiwQStWrFBubq4/x4wZM7R161Y999xzOnLkiJ566int27dP06ZN+7F3CQAACFGRdr74vn37NGLECP/zpiKTlZWl/Px8zZkzRzU1NXr00Ud19uxZ3Xzzzdq6davatm3r/5nXXntN06ZN08iRIxUeHq7x48frhRde8K+PiYnRO++8o5ycHKWlpalLly5asGBBwL2c/vmf/1nr1q3Tk08+qV/+8pfq3bu33nrrLfXr1+9H2AsAAOBqEDL3abracZ8moHXjPk1A69Qq7tMEAAAQSihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABihNAAAABiLtDgAAV4PkeQV2R7hsny7OtDsC0KpwpgkAAMAApQkAAMAApQkAAMAApQkAAMAApQkAAMAApQkAAMAApQkAAMAApQkAAMAApQkAAMAApQkAAMAApQkAAMAApQkAAMAApQkAAMAApQkAAMAApQkAAMAApQkAAMAApQkAAMAApQkAAMAApQkAAMAApQkAAMAApQkAAMBApN0BAABXRvK8ArsjXLZPF2faHQH4VpxpAgAAMEBpAgAAMEBp+oZVq1YpOTlZbdu2VXp6uvbu3Wt3JAAAEAIoTRfZsGGDcnNztXDhQu3fv18DBw6U2+3W6dOn7Y4GAABsRmm6yLJly/TII49oypQpSk1N1Zo1a9S+fXu9/PLLdkcDAAA249tzf1dfX6+SkhLNnz/fvyw8PFwZGRkqLi5uNl9XV6e6ujr/8+rqakmS1+u9Ivl8dV9eke0CQCjpMWuj3REu26FFbrsj4Ado+r1tWdb3zlKa/u6zzz5TY2Oj4uPjA5bHx8fryJEjzebz8vK0aNGiZsuTkpKuWEYAQOiJWW53ArSEc+fOKSYm5jtnKE1Bmj9/vnJzc/3PfT6fvvjiC3Xu3FlhYWEt+lper1dJSUk6ceKEnE5ni267tWFfmWNfmWNfmWNfmWNfXZ4rtb8sy9K5c+eUmJj4vbOUpr/r0qWLIiIiVFlZGbC8srJSCQkJzeajoqIUFRUVsKxTp05XMqKcTif/YRliX5ljX5ljX5ljX5ljX12eK7G/vu8MUxMuBP87h8OhtLQ0FRYW+pf5fD4VFhbK5XLZmAwAAIQCzjRdJDc3V1lZWRoyZIiGDRum5cuXq6amRlOmTLE7GgAAsBml6SITJkxQVVWVFixYII/Ho0GDBmnr1q3NLg7/sUVFRWnhwoXNPg5Ec+wrc+wrc+wrc+wrc+yryxMK+yvMMvmOHQAAwDWOa5oAAAAMUJoAAAAMUJoAAAAMUJoAAAAMUJpC3KpVq5ScnKy2bdsqPT1de/futTtSSHrqqacUFhYW8Ojbt6/dsULC7t27deeddyoxMVFhYWF66623AtZblqUFCxaoW7duateunTIyMnT06FF7wtrs+/bVgw8+2Ow4Gz16tD1hbZaXl6ehQ4cqOjpacXFxGjt2rMrKygJmamtrlZOTo86dO6tjx44aP358sxsIXwtM9tXPfvazZsfW1KlTbUpsnxdffFEDBgzw38DS5XJpy5Yt/vV2H1OUphC2YcMG5ebmauHChdq/f78GDhwot9ut06dP2x0tJP30pz/VqVOn/I93333X7kghoaamRgMHDtSqVasuuX7JkiV64YUXtGbNGu3Zs0cdOnSQ2+1WbW3tj5zUft+3ryRp9OjRAcfZ66+//iMmDB1FRUXKycnR+++/r+3bt6uhoUGjRo1STU2Nf2bWrFl6++23tXHjRhUVFamiokLjxo2zMbU9TPaVJD3yyCMBx9aSJUtsSmyf7t27a/HixSopKdG+fft022236a677tLhw4clhcAxZSFkDRs2zMrJyfE/b2xstBITE628vDwbU4WmhQsXWgMHDrQ7RsiTZG3atMn/3OfzWQkJCdbSpUv9y86ePWtFRUVZr7/+ug0JQ8c395VlWVZWVpZ111132ZIn1J0+fdqSZBUVFVmW9fVx1KZNG2vjxo3+mb/85S+WJKu4uNiumCHhm/vKsizrX/7lX6wZM2bYFyqEXXfdddZLL70UEscUZ5pCVH19vUpKSpSRkeFfFh4eroyMDBUXF9uYLHQdPXpUiYmJ+slPfqJJkyapvLzc7kgh7/jx4/J4PAHHWUxMjNLT0znOvsWuXbsUFxenPn366LHHHtPnn39ud6SQUF1dLUmKjY2VJJWUlKihoSHg2Orbt6969OhxzR9b39xXTV577TV16dJF/fr10/z58/Xll1/aES9kNDY2av369aqpqZHL5QqJY4o7goeozz77TI2Njc3uRh4fH68jR47YlCp0paenKz8/X3369NGpU6e0aNEi3XLLLTp06JCio6PtjheyPB6PJF3yOGtah38YPXq0xo0bp5SUFB07dky//OUvdfvtt6u4uFgRERF2x7ONz+fTzJkzddNNN6lfv36Svj62HA5Hsz9kfq0fW5faV5J03333qWfPnkpMTNSBAwc0d+5clZWV6c0337QxrT0OHjwol8ul2tpadezYUZs2bVJqaqpKS0ttP6YoTWgVbr/9dv+/BwwYoPT0dPXs2VNvvPGGsrOzbUyG1mTixIn+f/fv318DBgzQ9ddfr127dmnkyJE2JrNXTk6ODh06xHWEBr5tXz366KP+f/fv31/dunXTyJEjdezYMV1//fU/dkxb9enTR6WlpaqurtYf/vAHZWVlqaioyO5YkrgQPGR16dJFERERzb4VUFlZqYSEBJtSXT06deqkG264QZ988ondUUJa07HEcRacn/zkJ+rSpcs1fZxNmzZNmzdv1s6dO9W9e3f/8oSEBNXX1+vs2bMB89fysfVt++pS0tPTJemaPLYcDod69eqltLQ05eXlaeDAgVqxYkVIHFOUphDlcDiUlpamwsJC/zKfz6fCwkK5XC4bk10dzp8/r2PHjqlbt252RwlpKSkpSkhICDjOvF6v9uzZw3Fm4OTJk/r888+vyePMsixNmzZNmzZt0o4dO5SSkhKwPi0tTW3atAk4tsrKylReXn7NHVvft68upbS0VJKuyWPrm3w+n+rq6kLimOLjuRCWm5urrKwsDRkyRMOGDdPy5ctVU1OjKVOm2B0t5MyePVt33nmnevbsqYqKCi1cuFARERG699577Y5mu/Pnzwf83+rx48dVWlqq2NhY9ejRQzNnztQzzzyj3r17KyUlRb/61a+UmJiosWPH2hfaJt+1r2JjY7Vo0SKNHz9eCQkJOnbsmObMmaNevXrJ7XbbmNoeOTk5Wrdunf74xz8qOjraf01JTEyM2rVrp5iYGGVnZys3N1exsbFyOp2aPn26XC6Xhg8fbnP6H9f37atjx45p3bp1GjNmjDp37qwDBw5o1qxZuvXWWzVgwACb0/+45s+fr9tvv109evTQuXPntG7dOu3atUvbtm0LjWPqR/mOHoL2H//xH1aPHj0sh8NhDRs2zHr//fftjhSSJkyYYHXr1s1yOBzWP/3TP1kTJkywPvnkE7tjhYSdO3dakpo9srKyLMv6+rYDv/rVr6z4+HgrKirKGjlypFVWVmZvaJt817768ssvrVGjRlldu3a12rRpY/Xs2dN65JFHLI/HY3dsW1xqP0my1q5d65/56quvrF/84hfWddddZ7Vv3966++67rVOnTtkX2ibft6/Ky8utW2+91YqNjbWioqKsXr16WU888YRVXV1tb3AbPPTQQ1bPnj0th8Nhde3a1Ro5cqT1zjvv+NfbfUyFWZZl/Tj1DAAA4OrFNU0AAAAGKE0AAAAGKE0AAAAGKE0AAAAGKE0AAAAGKE0AAAAGKE0AAAAGKE0AAAAGKE0AAAAGKE0AAAAGKE0AAAAGKE0AAAAG/h9OqcxjzMXKQgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution of line numbers\n",
    "train_df.line_number.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the distribution of the `\"line_number\"` column, it looks like the majority of lines have a position of 15 or less.\n",
    "\n",
    "Knowing this, let's set the `depth` parameter of `tf.one_hot` to 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GqXjPQfxH57h",
    "outputId": "428a9797-4a71-4894-b083-3fe507ee8613"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10, 15), dtype=float32, numpy=\n",
       " array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
       "       dtype=float32)>,\n",
       " TensorShape([180040, 15]))"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use tensorflow to create one hot encoded tensors of our \"line_number\" column\n",
    "train_line_numbers_one_hot = tf.one_hot(train_df.line_number.to_numpy(), depth=15)\n",
    "val_line_numbers_one_hot = tf.one_hot(val_df.line_number.to_numpy(), depth=15)\n",
    "test_line_numbers_one_hot = tf.one_hot(test_df.line_number.to_numpy(), depth=15)\n",
    "\n",
    "train_line_numbers_one_hot[:10], train_line_numbers_one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1DaWuIeJP4_"
   },
   "source": [
    "Setting the `depth` parameter of `tf.one_hot` to 15 means any sample with a `\"line_number\"` value of over 15 gets set to a tensor of all 0's, where as any sample with a `\"line_number\"` of under 15 gets turned into a tensor of all 0's but with a 1 at the index equal to the `\"line_number\"` value.\n",
    "\n",
    "> ðŸ”‘ **Note:** We could create a one-hot tensor which has room for all of the potential values of `\"line_number\"` (`depth=30`), however, this would end up in a tensor of double the size of our current one (`depth=15`) where the vast majority of values are 0. Plus, only ~2,000/180,000 samples have a `\"line_number\"` value of over 15. So we would not be gaining much information about our data for doubling our feature space. This kind of problem is called the **curse of dimensionality**. However, since this we're working with deep models, it might be worth trying to throw as much information at the model as possible and seeing what happens. I'll leave exploring values of the `depth` parameter as an extension.\n",
    "\n",
    "We can do the same as we've done for our `\"line_number\"` column witht he `\"total_lines\"` column. First, let's find an appropriate value for the `depth` parameter of `tf.one_hot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BJmZv8cIVmy",
    "outputId": "39a31a10-2e51-462c-af27-17e4bad22584"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11    24468\n",
       "10    23639\n",
       "12    22113\n",
       "9     19400\n",
       "13    18438\n",
       "14    14610\n",
       "8     12285\n",
       "15    10768\n",
       "7      7464\n",
       "16     7429\n",
       "17     5202\n",
       "6      3353\n",
       "18     3344\n",
       "19     2480\n",
       "20     1281\n",
       "5      1146\n",
       "21      770\n",
       "22      759\n",
       "23      264\n",
       "4       215\n",
       "24      200\n",
       "25      182\n",
       "26       81\n",
       "28       58\n",
       "3        32\n",
       "30       31\n",
       "27       28\n",
       "Name: total_lines, dtype: int64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many different total lines are there?\n",
    "train_df.total_lines.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "CjBNyi7MJAj6",
    "outputId": "61ad220b-e34e-4598-c352-2ae5ceed92e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution of \"total_lines\" column\n",
    "train_df.total_lines.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the distribution of our `\"total_lines\"` column, a value of 20 looks like it covers the majority of samples.\n",
    "\n",
    "We can confirm this with [`np.percentile()`](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-ftf-VsJH8x",
    "outputId": "49614383-a1bc-4ce5-f595-ab3f0c74c162"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the coverage of \"total_lines\" value of 20\n",
    "np.percentile(train_df.total_lines, 95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful! Plenty of converage. Let's one-hot-encode our `\"total_lines\"` column just as we did our `\"line_number\"` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uM1fwkIvJzIb",
    "outputId": "c7d9ada1-80ee-466a-eeaf-cf7f8f84aeb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10, 20), dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]], dtype=float32)>,\n",
       " TensorShape([180040, 20]))"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use tensorflow to encode one hot tensors of our total lines feature\n",
    "train_lines_total_one_hot = tf.one_hot(train_df.total_lines.to_numpy(), depth=20)\n",
    "val_lines_total_one_hot = tf.one_hot(val_df.total_lines.to_numpy(), depth=20)\n",
    "test_lines_total_one_hot = tf.one_hot(test_df.total_lines.to_numpy(), depth=20)\n",
    "\n",
    "train_lines_total_one_hot[:10], train_lines_total_one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8M6r_vnKLrk"
   },
   "source": [
    "### Building a tribrid embedding model\n",
    "\n",
    "Woohoo! Positional embedding tensors ready.\n",
    "\n",
    "It's time to build the biggest model we've built yet. One which incorporates token embeddings, character embeddings and our newly crafted positional embeddings.\n",
    "\n",
    "We'll be venturing into uncovered territory but there will be nothing here you haven't practiced before.\n",
    "\n",
    "More specifically we're going to go through the following steps:\n",
    "\n",
    "1. Create a token-level model (similar to `model_1`)\n",
    "2. Create a character-level model (similar to `model_3` with a slight modification to reflect the paper)\n",
    "3. Create a `\"line_number\"` model (takes in one-hot-encoded `\"line_number\"` tensor and passes it through a non-linear layer)\n",
    "4. Create a `\"total_lines\"` model (takes in one-hot-encoded `\"total_lines\"` tensor and passes it through a non-linear layer)\n",
    "5. Combine (using [`layers.Concatenate`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate)) the outputs of 1 and 2 into a token-character-hybrid embedding and pass it series of output to Figure 1 and section 4.2 of [*Neural Networks for Joint Sentence Classification\n",
    "in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf)\n",
    "6. Combine (using [`layers.Concatenate`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate)) the outputs of 3, 4 and 5 into a token-character-positional tribrid embedding \n",
    "7. Create an output layer to accept the tribrid embedding and output predicted label probabilities\n",
    "8. Combine the inputs of 1, 2, 3, 4 and outputs of 7 into a [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model)\n",
    "\n",
    "Woah! That's alot... but nothing we're not capable of. Let's code it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwOpYSWVLnGL",
    "outputId": "3ee87d7b-bf70-4e22-c4a7-0f6a81c5eec5"
   },
   "outputs": [],
   "source": [
    "# 1. Token inputs\n",
    "token_inputs = layers.Input(shape=[], dtype=tf.string)\n",
    "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
    "token_outputs = layers.Dense(128, activation='relu')(token_embeddings)\n",
    "token_model = tf.keras.Model(token_inputs,\n",
    "                             token_outputs)\n",
    "\n",
    "# 2. Char inputs\n",
    "char_inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "char_vectors = char_vec(char_inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "char_bi_lstm = layers.Bidirectional(layers.LSTM(24))(char_embeddings)\n",
    "char_model = tf.keras.Model(char_inputs,\n",
    "                            char_bi_lstm)\n",
    "\n",
    "# 3. Line number model\n",
    "line_number_inputs = layers.Input(shape=(15, ), dtype=tf.float32)\n",
    "line_number_outputs = layers.Dense(32, activation='relu')(line_number_inputs)\n",
    "line_number_model = tf.keras.Model(line_number_inputs,\n",
    "                                   line_number_outputs)\n",
    "\n",
    "# 4. Total lines model\n",
    "total_lines_inputs = layers.Input(shape=(20, ), dtype=tf.float32)\n",
    "total_lines_outputs = layers.Dense(32, activation='relu')(total_lines_inputs)\n",
    "total_lines_model = tf.keras.Model(total_lines_inputs,\n",
    "                                   total_lines_outputs)\n",
    "\n",
    "# 5. Combine models 1 and 2\n",
    "combined_embeddings = layers.Concatenate(name='char_token_hybrid_embedding')([token_model.output, char_model.output])\n",
    "z = layers.Dense(256, activation='relu')(combined_embeddings)\n",
    "z = layers.Dropout(0.5)(z)\n",
    "\n",
    "# 6. Combine positional embedding with combined token and char embeddings\n",
    "tribrid_embeddings = layers.Concatenate(name='char_token_positional_embeddings')([line_number_model.output,\n",
    "                                                                                 total_lines_model.output,\n",
    "                                                                                 z])\n",
    "\n",
    "# 7. Create output layer\n",
    "output_layer = layers.Dense(5, activation='softmax', name='output_layer')(tribrid_embeddings)\n",
    "\n",
    "# 8. Get it all together\n",
    "model_5 = tf.keras.Model(inputs=[line_number_model.input,\n",
    "                                 total_lines_model.input,\n",
    "                                 token_model.input,\n",
    "                                 char_model.inputs],\n",
    "                         outputs=output_layer,\n",
    "                         name='model_5_tribrid_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot going on here... let's visualize what's happening with a summary by plotting our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "j1B3vF3JQpAS",
    "outputId": "389907f9-86fe-47c1-cd55-5a93c1c88f8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# Visualize the model\n",
    "plot_model(model_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the model makes it much easier to understand.\n",
    "\n",
    "Essentially what we're doing is trying to encode as much information about our sequences as possible into various embeddings (the inputs to our model) so our model has the best chance to figure out what label belongs to a sequence (the outputs of our model).\n",
    "\n",
    "You'll notice our model is looking very similar to the model shown in Figure 1 of [*Neural Networks for Joint Sentence Classification\n",
    "in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf). However, a few differences still remain:\n",
    "* We're using pretrained TensorFlow Hub token embeddings instead of GloVe emebddings.\n",
    "* We're using a Dense layer on top of our token-character hybrid embeddings instead of a bi-LSTM layer.\n",
    "* Section 3.1.3 of the paper mentions a label sequence optimization layer (which helps to make sure sequence labels come out in a respectable order) but it isn't shown in Figure 1. To makeup for the lack of this layer in our model, we've created the positional embeddings layers.\n",
    "* Section 4.2 of the paper mentions the token and character embeddings are updated during training, our pretrained TensorFlow Hub embeddings remain frozen.\n",
    "* The paper uses the [`SGD`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) optimizer, we're going to stick with [`Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam).\n",
    "\n",
    "All of the differences above are potential extensions of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "id": "0uLCNdfGROHt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_tribrid_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " character_vectorizer (TextVect  (None, 290)         0           ['input_11[0][0]']               \n",
      " orization)                                                                                       \n",
      "                                                                                                  \n",
      " universal_sentence_encoder (Ke  (None, 512)         256797824   ['input_10[0][0]']               \n",
      " rasLayer)                                                                                        \n",
      "                                                                                                  \n",
      " char_embed (Embedding)         (None, 290, 25)      700         ['character_vectorizer[2][0]']   \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 128)          65664       ['universal_sentence_encoder[2][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 48)          9600        ['char_embed[2][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " char_token_hybrid_embedding (C  (None, 176)         0           ['dense_12[0][0]',               \n",
      " oncatenate)                                                      'bidirectional_2[0][0]']        \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 15)]         0           []                               \n",
      "                                                                                                  \n",
      " input_13 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 256)          45312       ['char_token_hybrid_embedding[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 32)           512         ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 32)           672         ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 256)          0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " char_token_positional_embeddin  (None, 320)         0           ['dense_13[0][0]',               \n",
      " gs (Concatenate)                                                 'dense_14[0][0]',               \n",
      "                                                                  'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, 5)            1605        ['char_token_positional_embedding\n",
      "                                                                 s[0][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 256,921,889\n",
      "Trainable params: 124,065\n",
      "Non-trainable params: 256,797,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the model summary\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHRxJmaxTgCW"
   },
   "source": [
    "Now our model is constructed, let's compile it.\n",
    "\n",
    "This time, we're going to introduce a new parameter to our loss function called `label_smoothing`. Label smoothing helps to regularize our model (prevent overfitting) by making sure it doesn't get too focused on applying one particular label to a sample.\n",
    "\n",
    "For example, instead of having an output prediction of: \n",
    "* `[0.0, 0.0, 1.0, 0.0, 0.0]` for a sample (the model is very confident the right label is index 2).\n",
    "\n",
    "It's predictions will get smoothed to be something like:\n",
    "* `[0.01, 0.01, 0.096, 0.01, 0.01]` giving a small activation to each of the other labels, in turn, hopefully improving generalization.\n",
    "\n",
    "> ðŸ“– **Resource:** For more on label smoothing, see the great blog post by PyImageSearch, [*Label smoothing with Keras, TensorFlow, and Deep Learning*](https://www.pyimagesearch.com/2019/12/30/label-smoothing-with-keras-tensorflow-and-deep-learning/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "id": "vvENrt4QRWJu"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_5.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2),\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tribrid embedding datasets and fit tribrid model\n",
    "\n",
    "Model compiled!\n",
    "\n",
    "However, we go all in this time! We shall fit on the entire training dataset for 5 epochs and validate on the entire validation dataset. This ensures we get the best possible results of our model architecture.\n",
    "\n",
    "This time our model requires four feature inputs:\n",
    "1. Train line numbers one-hot tensor (`train_line_numbers_one_hot`)\n",
    "2. Train total lines one-hot tensor (`train_total_lines_one_hot`)\n",
    "3. Token-level sequences tensor (`train_sentences`)\n",
    "4. Char-level sequences tensor (`train_chars`)\n",
    "\n",
    "We can pass these as tuples to our `tf.data.Dataset.from_tensor_slices()` method to create appropriately shaped and batched `PrefetchedDataset`'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "id": "lSRWwGR_R_F8"
   },
   "outputs": [],
   "source": [
    "# Create the tribrid data\n",
    "train_tribrid_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot,\n",
    "                                                         train_lines_total_one_hot,\n",
    "                                                         train_sentences,\n",
    "                                                         train_chars))\n",
    "train_tribrid_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot)\n",
    "train_tribrid_dataset = tf.data.Dataset.zip((train_tribrid_data, train_tribrid_labels))\n",
    "train_tribrid_dataset = train_tribrid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_tribrid_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,\n",
    "                                                       val_lines_total_one_hot,\n",
    "                                                       val_sentences, \n",
    "                                                       val_chars))\n",
    "val_tribrid_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
    "val_tribrid_dataset = tf.data.Dataset.zip((val_tribrid_data, val_tribrid_labels))\n",
    "val_tribrid_dataset = val_tribrid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_tribrid_data = tf.data.Dataset.from_tensor_slices((test_line_numbers_one_hot,\n",
    "                                                        test_lines_total_one_hot,\n",
    "                                                        test_sentences, \n",
    "                                                        test_chars))\n",
    "test_tribrid_labels = tf.data.Dataset.from_tensor_slices(test_labels_one_hot)\n",
    "test_tribrid_dataset = tf.data.Dataset.zip((test_tribrid_data, test_tribrid_labels))\n",
    "test_tribrid_dataset = test_tribrid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "id": "-GXnjciMWIw5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=((TensorSpec(shape=(None, 15), dtype=tf.float32, name=None), TensorSpec(shape=(None, 20), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tribrid_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnhGix-Id8b-"
   },
   "source": [
    "### Fitting, evaluating and making and making predictions with our tribrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2M6yQGA5Rg0Y",
    "outputId": "122d14f1-8523-4e4e-ae85-c1e01fe3b257"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5627/5627 [==============================] - 609s 107ms/step - loss: 0.9543 - accuracy: 0.8233 - val_loss: 0.9112 - val_accuracy: 0.8467\n",
      "Epoch 2/5\n",
      "5627/5627 [==============================] - 603s 107ms/step - loss: 0.9090 - accuracy: 0.8538 - val_loss: 0.8990 - val_accuracy: 0.8543\n",
      "Epoch 3/5\n",
      "5627/5627 [==============================] - 604s 107ms/step - loss: 0.8968 - accuracy: 0.8630 - val_loss: 0.8969 - val_accuracy: 0.8555\n",
      "Epoch 4/5\n",
      "5627/5627 [==============================] - 600s 107ms/step - loss: 0.8879 - accuracy: 0.8701 - val_loss: 0.8956 - val_accuracy: 0.8551\n",
      "Epoch 5/5\n",
      "5627/5627 [==============================] - 607s 108ms/step - loss: 0.8817 - accuracy: 0.8752 - val_loss: 0.8980 - val_accuracy: 0.8550\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history_5 = model_5.fit(train_tribrid_dataset,\n",
    "                        steps_per_epoch=len(train_tribrid_dataset),\n",
    "                        epochs=5,\n",
    "                        validation_data=val_tribrid_dataset,\n",
    "                        validation_steps=len(val_tribrid_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tribrid model trained! Time to make some predictions with it and evaluate them just as we've done before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SIYF4Ph3UEoy",
    "outputId": "ef4b5965-48c1-44e5-f7a5-e4576ed401d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 21s 22ms/step - loss: 0.8980 - accuracy: 0.8550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.898021936416626, 0.8549582958221436]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on whole validation dataset\n",
    "model_5.evaluate(val_tribrid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bTO-JCqeSK1",
    "outputId": "1475c96c-a664-45d0-be00-009eeed761b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 23s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.64752173, 0.10152699, 0.01045776, 0.22642185, 0.01407161],\n",
       "       [0.5953347 , 0.12120387, 0.03299953, 0.22916196, 0.02129991],\n",
       "       [0.40531662, 0.0875893 , 0.03141772, 0.4382671 , 0.03740926],\n",
       "       ...,\n",
       "       [0.0250094 , 0.06969805, 0.02156403, 0.03103577, 0.8526928 ],\n",
       "       [0.01605642, 0.30481806, 0.03212602, 0.02169464, 0.62530494],\n",
       "       [0.03659443, 0.9107479 , 0.02225734, 0.01626843, 0.014132  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions\n",
    "model_5_pred_probs = model_5.predict(val_tribrid_dataset)\n",
    "model_5_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_f_nmtYqeby7",
    "outputId": "7bb48498-cb14-40c9-f829-c5d54f6beac3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 4, 1], dtype=int64)>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn those predictions into labels\n",
    "model_5_preds = tf.argmax(model_5_pred_probs, axis=1)\n",
    "model_5_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5WxpZgWNemrr",
    "outputId": "a847bd84-82ac-48ac-d8ea-7eea00caf3e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 85.49582947173309,\n",
       " 'precision': 0.8569229795533327,\n",
       " 'recall': 0.8549582947173309,\n",
       " 'f1': 0.8521428894075217}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all evaluation metrics\n",
    "model_5_results = calculate_results(val_labels_encoded, model_5_preds)\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "id": "Lh6lM1GJge56",
    "outputId": "ad3706bd-43d4-4e9a-9389-b6ed552686a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.79557791605984,\n",
       " 'precision': 0.7307841312001448,\n",
       " 'recall': 0.7279557791605984,\n",
       " 'f1': 0.723641494719868}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "--Kxw8CiezYB",
    "outputId": "18465564-2a94-403d-f8e2-e659e89b5868"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 72.1832384482987,\n",
       " 'precision': 0.7186466952323352,\n",
       " 'recall': 0.7218323844829869,\n",
       " 'f1': 0.6989250353450294}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TdozSTPhUa-"
   },
   "source": [
    "## Compare model results \n",
    "\n",
    "Far out, we've come a long way. From a baseline model to training a model containing three different kinds of embeddings.\n",
    "\n",
    "Now it's time to compare each model's performance against each other.\n",
    "\n",
    "We'll also be able to compare our model's to the [*PubMed 200k RCT:\n",
    "a Dataset for Sequential Sentence Classification in Medical Abstracts*](https://arxiv.org/pdf/1710.06071.pdf) paper.\n",
    "\n",
    "Since all of our model results are in dictionaries, let's combine them into a pandas DataFrame to visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "id": "Uw9ym98DhTj_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>72.183238</td>\n",
       "      <td>0.718647</td>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.698925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom_token_embed_conv1d</th>\n",
       "      <td>78.402621</td>\n",
       "      <td>0.781074</td>\n",
       "      <td>0.784026</td>\n",
       "      <td>0.781842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretrained_token_embed</th>\n",
       "      <td>71.544419</td>\n",
       "      <td>0.715588</td>\n",
       "      <td>0.715444</td>\n",
       "      <td>0.712533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom_char_embed_conv1d</th>\n",
       "      <td>44.876208</td>\n",
       "      <td>0.376848</td>\n",
       "      <td>0.448762</td>\n",
       "      <td>0.392351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hybrid_char_token_embed</th>\n",
       "      <td>72.795578</td>\n",
       "      <td>0.730784</td>\n",
       "      <td>0.727956</td>\n",
       "      <td>0.723641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tribrid_pos_char_token_embed</th>\n",
       "      <td>85.495829</td>\n",
       "      <td>0.856923</td>\n",
       "      <td>0.854958</td>\n",
       "      <td>0.852143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               accuracy  precision    recall        f1\n",
       "baseline                      72.183238   0.718647  0.721832  0.698925\n",
       "custom_token_embed_conv1d     78.402621   0.781074  0.784026  0.781842\n",
       "pretrained_token_embed        71.544419   0.715588  0.715444  0.712533\n",
       "custom_char_embed_conv1d      44.876208   0.376848  0.448762  0.392351\n",
       "hybrid_char_token_embed       72.795578   0.730784  0.727956  0.723641\n",
       "tribrid_pos_char_token_embed  85.495829   0.856923  0.854958  0.852143"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine model results into a DataFrame\n",
    "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
    "                                  \"custom_token_embed_conv1d\": model_1_results,\n",
    "                                  \"pretrained_token_embed\": model_2_results,\n",
    "                                  \"custom_char_embed_conv1d\": model_3_results,\n",
    "                                  \"hybrid_char_token_embed\": model_4_results,\n",
    "                                  \"tribrid_pos_char_token_embed\": model_5_results})\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "id": "veXFIOOIheCE"
   },
   "outputs": [],
   "source": [
    "# Reduce the accuracy to same scale as other metrics\n",
    "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "id": "9Lq38wZrhgVB"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and compare all of the model results\n",
    "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xh6nm5FLhif3"
   },
   "source": [
    "Since the [*PubMed 200k RCT:\n",
    "a Dataset for Sequential Sentence Classification in Medical Abstracts*](https://arxiv.org/pdf/1710.06071.pdf) paper compares their tested model's F1-scores on the test dataset, let's take at our model's F1-scores.\n",
    "\n",
    "> ðŸ”‘ **Note:** We could've also made these comparisons in TensorBoard using the [`TensorBoard`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) callback during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "id": "5SPyDS3JhlZ-"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort model results by f1-score\n",
    "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5MDdJoXhm8F"
   },
   "source": [
    "Nice! Based on F1-scores, it looks like our tribrid embedding model performs the best by a fair margin.\n",
    "\n",
    "Though, in comparison to the results reported in Table 3 of the [*PubMed 200k RCT:\n",
    "a Dataset for Sequential Sentence Classification in Medical Abstracts*](https://arxiv.org/pdf/1710.06071.pdf) paper, our model's F1-score is still underperforming (the authors model achieves an F1-score of 90.0 on the 20k RCT dataset versus our F1-score of ~82.6).\n",
    "\n",
    "There are some things to note about this difference:\n",
    "* Our models (with an exception for the baseline) have been trained on ~18,000 (10% of batches) samples of sequences and labels rather than the full ~180,000 in the 20k RCT dataset.\n",
    "  * This is often the case in machine learning experiments though, make sure training works on a smaller number of samples, then upscale when needed (an extension to this project will be training a model on the full dataset).\n",
    "* Our model's prediction performance levels have been evaluated on the validation dataset not the test dataset (we'll evaluate our best model on the test dataset shortly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGBX6ZOHhpJ5"
   },
   "source": [
    "## Save and load best performing model\n",
    "\n",
    "Since we've been through a fair few experiments, it's a good idea to save our best performing model so we can reuse it without having to retrain it.\n",
    "\n",
    "We can save our best performing model by calling the [`save()`](https://www.tensorflow.org/guide/keras/save_and_serialize#the_short_answer_to_saving_loading) method on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0T4KsoDxhxwN",
    "outputId": "7aee6163-405b-401f-a323-e01950d70a91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: skimlit_tribrid_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: skimlit_tribrid_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save best performing model to SavedModel format (default)\n",
    "model_5.save(\"skimlit_tribrid_model\") # model will be saved to path specified by string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykp3f6AAhzPN"
   },
   "source": [
    "Optional: If you're using Google Colab, you might want to copy your saved model to Google Drive (or [download it](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=hauvGV4hV-Mh)) for more permanent storage (Google Colab files disappear after you disconnect).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "id": "Jac5xMj6h3I3"
   },
   "outputs": [],
   "source": [
    "# Example of copying saved model from Google Colab to Drive (requires Google Drive to be mounted)\n",
    "# !cp skim_lit_best_model -r /content/drive/MyDrive/tensorflow_course/skim_lit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dARML4Ah6_E"
   },
   "source": [
    "\n",
    "Like all good cooking shows, we've got a pretrained model (exactly the same kind of model we built for `model_5` [saved and stored on Google Storage](https://storage.googleapis.com/ztm_tf_course/skimlit/skimlit_best_model.zip)). \n",
    "\n",
    "So to make sure we're all using the same model for evaluation, we'll download it and load it in. \n",
    "\n",
    "And when loading in our model, since it uses a couple of [custom objects](https://www.tensorflow.org/guide/keras/save_and_serialize#custom_objects) (our TensorFlow Hub layer and `TextVectorization` layer), we'll have to load it in by specifying them in the `custom_objects` parameter of [`tf.keras.models.load_model()`](https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "id": "RVONK4oWh89S"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Download pretrained model from Google Storage\n",
    "!curl https://storage.googleapis.com/ztm_tf_course/skimlit/skimlit_tribrid_model.zip\n",
    "!mkdir skimlit_gs_model\n",
    "!unzip skimlit_tribrid_model.zip -d skimlit_gs_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "id": "WjyCt6n1iDVf"
   },
   "outputs": [],
   "source": [
    "# Import TensorFlow model dependencies (if needed) - https://github.com/tensorflow/tensorflow/issues/38250 \n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from keras.layers import TextVectorization\n",
    "\n",
    "model_path = \"skimlit_tribrid_model\"\n",
    "\n",
    "# Load downloaded model from Google Storage\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "                                          # Note: with TensorFlow 2.5+ if your SavedModel has a keras_metadata.pb file \n",
    "                                          # (created when using model.save()), you shouldn't need the custom_objects\n",
    "                                          # parameter. I'm leaving the code below here in case you do.\n",
    "                                          # custom_objects={\"TextVectorization\": TextVectorization, # required for char vectorization\n",
    "                                          #                 \"KerasLayer\": hub.KerasLayer}) # required for token embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mqP3KmOiH3f"
   },
   "source": [
    "### Make predictions and evalaute them against the truth labels\n",
    "\n",
    "To make sure our model saved and loaded correctly, let's make predictions with it, evaluate them and then compare them to the prediction results we calculated earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jTfAm6U0iVbj",
    "outputId": "95694601-e93a-4e73-af84-3f20d8f92b30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 27s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 0, 3, 2, 2, 4, 4, 4, 4, 1], dtype=int64)>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the loaded model on the validation set\n",
    "loaded_pred_probs = loaded_model.predict(val_tribrid_dataset, verbose=1)\n",
    "loaded_preds = tf.argmax(loaded_pred_probs, axis=1)\n",
    "loaded_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKHGf2kBiW-0",
    "outputId": "8174c7f8-00c0-4a66-c226-b885e48ac38c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 85.49582947173309,\n",
       " 'precision': 0.8569229795533327,\n",
       " 'recall': 0.8549582947173309,\n",
       " 'f1': 0.8521428894075217}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate loaded model's predictions\n",
    "loaded_model_results = calculate_results(val_labels_encoded,\n",
    "                                         loaded_preds)\n",
    "loaded_model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2ejz5WhiYas"
   },
   "source": [
    "Now let's compare our loaded model's predictions with the prediction results we obtained before saving our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IT05qXdOiabZ",
    "outputId": "eaa924b4-c9c0-4942-ff78-1663f760a87f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare loaded model results with original trained model results (should be quite close)\n",
    "np.isclose(list(model_5_results.values()), list(loaded_model_results.values()), rtol=1e-02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jdom2fvQici-"
   },
   "source": [
    "It's worth noting that loading in a SavedModel unfreezes all layers (makes them all trainable). So if you want to freeze any layers, you'll have to set their trainable attribute to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQz1k48mi57U",
    "outputId": "1f4b474b-514a-4661-ba60-398bd512ccee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_tribrid_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " character_vectorizer (TextVect  (None, 290)         0           ['input_11[0][0]']               \n",
      " orization)                                                                                       \n",
      "                                                                                                  \n",
      " universal_sentence_encoder (Ke  (None, 512)         256797824   ['input_10[0][0]']               \n",
      " rasLayer)                                                                                        \n",
      "                                                                                                  \n",
      " char_embed (Embedding)         (None, 290, 25)      700         ['character_vectorizer[0][0]']   \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 128)          65664       ['universal_sentence_encoder[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 48)          9600        ['char_embed[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " char_token_hybrid_embedding (C  (None, 176)         0           ['dense_12[0][0]',               \n",
      " oncatenate)                                                      'bidirectional_2[0][0]']        \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 15)]         0           []                               \n",
      "                                                                                                  \n",
      " input_13 (InputLayer)          [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 256)          45312       ['char_token_hybrid_embedding[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 32)           512         ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 32)           672         ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 256)          0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " char_token_positional_embeddin  (None, 320)         0           ['dense_13[0][0]',               \n",
      " gs (Concatenate)                                                 'dense_14[0][0]',               \n",
      "                                                                  'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, 5)            1605        ['char_token_positional_embedding\n",
      "                                                                 s[0][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 256,921,889\n",
      "Trainable params: 124,065\n",
      "Non-trainable params: 256,797,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check loaded model summary (note the number of trainable parameters)\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8mt27-Yi8Z_"
   },
   "source": [
    "## Evaluate model on test dataset\n",
    "\n",
    "To make our model's performance more comparable with the results reported in Table 3 of the [*PubMed 200k RCT:\n",
    "a Dataset for Sequential Sentence Classification in Medical Abstracts*](https://arxiv.org/pdf/1710.06071.pdf) paper, let's make predictions on the test dataset and evaluate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "De465TOKi-_K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942/942 [==============================] - 22s 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([3, 2, 2, 2, 4, 4, 4, 1, 1, 0], dtype=int64)>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the test dataset\n",
    "test_pred_probs = model_5.predict(test_tribrid_dataset,\n",
    "                                       verbose=1)\n",
    "test_preds = tf.argmax(test_pred_probs, axis=1)\n",
    "test_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "id": "qIzV8Bm9jHiK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 84.94773519163763,\n",
       " 'precision': 0.850028122508686,\n",
       " 'recall': 0.8494773519163763,\n",
       " 'f1': 0.8463609452610964}"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate loaded model test predictions\n",
    "loaded_model_test_results = calculate_results(y_true=test_labels_encoded,\n",
    "                                              y_pred=test_preds)\n",
    "loaded_model_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kx7Op9NjjMRX"
   },
   "source": [
    "It seems our best model (so far) still has some ways to go to match the performance of the results in the paper (their model gets 90.0 F1-score on the test dataset, where as ours gets ~82.1 F1-score).\n",
    "\n",
    "However, as we discussed before our model has only been trained on 20,000 out of the total ~180,000 sequences in the RCT 20k dataset. We also haven't fine-tuned our pretrained embeddings (the paper fine-tunes GloVe embeddings). So there's a couple of extensions we could try to improve our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAAJprHcl9nm"
   },
   "source": [
    "## Prettifying Our Work âœ¨\n",
    "\n",
    "At some point for the deployment of our project, we will need to tidy up everything and create a single function to do our entire task.\n",
    "Therefore, we will be implementing the same below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMi8z9YUWyWU"
   },
   "source": [
    "We will be using this abstract as a test:\n",
    "> Extracellular deposition of amyloid-Î² as neuritic plaques and intracellular accumulation of hyperphosphorylated, aggregated tau as neurofibrillary tangles are two of the characteristic hallmarks of Alzheimer's disease. The regional progression of brain atrophy in Alzheimer's disease highly correlates with tau accumulation but not amyloid deposition, and the mechanisms of tau-mediated neurodegeneration remain elusive. Innate immune responses represent a common pathway for the initiation and progression of some neurodegenerative diseases. So far, little is known about the extent or role of the adaptive immune response and its interaction with the innate immune response in the presence of amyloid-Î² or tau pathology. Here we systematically compared the immunological milieux in the brain of mice with amyloid deposition or tau aggregation and neurodegeneration. We found that mice with tauopathy but not those with amyloid deposition developed a unique innate and adaptive immune response and that depletion of microglia or T cells blocked tau-mediated neurodegeneration. Numbers of T cells, especially those of cytotoxic T cells, were markedly increased in areas with tau pathology in mice with tauopathy and in the Alzheimer's disease brain. T cell numbers correlated with the extent of neuronal loss, and the cells dynamically transformed their cellular characteristics from activated to exhausted states along with unique TCR clonal expansion. Inhibition of interferon-Î³ and PDCD1 signalling both significantly ameliorated brain atrophy. Our results thus reveal a tauopathy- and neurodegeneration-related immune hub involving activated microglia and T cell responses, which could serve as therapeutic targets for preventing neurodegeneration in Alzheimer's disease and primary tauopathies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "id": "v5rwtAS9W7f8"
   },
   "outputs": [],
   "source": [
    "test_abstract = \"Adipose-derived stromal cell (ASC), known as one of the mesenchymal stem cells (MSCs), is a promising tool for regenerative medicine; however, the effect of ASCs on tumor growth has not been studied sufficiently. We investigated the hypothesis that ASCs have an inhibitory effect on metastatic tumor progression. To evaluate the in vitro inhibitory effect of ASCs on metastatic prostate cancer (PCa), direct coculture and indirect separate culture experiments with PC3M-luc2 cells and human ASCs were performed, and ASCs were administered to PC3M-luc2 cell-derived tumor-bearing nude mice for in vivo experiment. We also performed exosome microRNA (miRNA) array analysis to explore a mechanistic insight into the effect of ASCs on PCa cell proliferation/apoptosis. Both in vitro and in vivo experiments exhibited the inhibitory effect of ASCs on PC3M-luc2 cell proliferation, inducing apoptosis and PCa growth, respectively. Among upregulated miRNAs in ASCs compared with fibroblasts, we focused on miR-145, which was known as a tumor suppressor. ASC-derived conditioned medium (CM) significantly inhibited PC3M-luc2 cell proliferation, inducing apoptosis, but the effect was canceled by miR-145 knockdown in ASCs. ASC miR-145 knockdown CM also reduced the expression of Caspase 3/7 with increased antiapoptotic protein, BclxL, expression in PC3M-luc2 cells. This study provides preclinical data that ASCs inhibit PCa growth, inducing PCa cell apoptosis with reduced activity of BclxL, at least in part, by miR-145, including exosomes released from ASCs, suggesting that ASC administration could be a novel and promising therapeutic strategy in patients with PCa.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "id": "ulzYXXxGXN-d"
   },
   "outputs": [],
   "source": [
    "def get_results(abs_text):\n",
    "    labels = ['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS']\n",
    "    sent_list = abs_text.split(sep='.')\n",
    "    sent_list.pop()\n",
    "    sent_list = [sentence.strip() for sentence in sent_list]\n",
    "    i = 0\n",
    "    total_lines = len(sent_list)\n",
    "    final_list = []\n",
    "    temp = {}\n",
    "    for line in sent_list:\n",
    "        temp['text'] = line\n",
    "        temp['line_number'] = i\n",
    "        temp['total_lines'] = total_lines\n",
    "        i += 1\n",
    "        final_list.append(temp)\n",
    "        temp = {}\n",
    "    df = pd.DataFrame(final_list)\n",
    "    chars = [\" \".join(list(sentence)) for sentence in sent_list]\n",
    "    line_numbers_one_hot = tf.one_hot(df.line_number.to_numpy(), depth=15)\n",
    "    lines_total_one_hot = tf.one_hot(df.total_lines.to_numpy(), depth=20)\n",
    "    preds = tf.argmax(loaded_model.predict(x=(line_numbers_one_hot,\n",
    "                                         lines_total_one_hot,\n",
    "                                         tf.constant(sent_list),\n",
    "                                         tf.constant(chars)),\n",
    "                                         verbose=0),\n",
    "                    axis=1)\n",
    "    print('\\033[1mABSTRACT\\n')\n",
    "    i = 0\n",
    "    for i in range(0, total_lines):\n",
    "        if i!=0 and preds[i]!=preds[i-1]:\n",
    "            print(f'\\n\\n\\033[1m{labels[preds[i]]}:', end=' ')\n",
    "            print(f'\\033[0m{sent_list[i]}.', end=' ')\n",
    "        elif i==0:\n",
    "            print(f'\\033[1m{labels[preds[i]]}:', end=' ')\n",
    "            print(f'\\033[0m{sent_list[i]}.', end=' ')\n",
    "        else:\n",
    "            print(f'{sent_list[i]}.', end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDDwHOIPaMLF",
    "outputId": "f3d4e8ff-8a8b-40ff-bae0-d313928c016c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mABSTRACT\n",
      "\n",
      "\u001b[1mBACKGROUND: \u001b[0mAdipose-derived stromal cell (ASC), known as one of the mesenchymal stem cells (MSCs), is a promising tool for regenerative medicine; however, the effect of ASCs on tumor growth has not been studied sufficiently. We investigated the hypothesis that ASCs have an inhibitory effect on metastatic tumor progression. \n",
      "\n",
      "\u001b[1mOBJECTIVE: \u001b[0mTo evaluate the in vitro inhibitory effect of ASCs on metastatic prostate cancer (PCa), direct coculture and indirect separate culture experiments with PC3M-luc2 cells and human ASCs were performed, and ASCs were administered to PC3M-luc2 cell-derived tumor-bearing nude mice for in vivo experiment. \n",
      "\n",
      "\u001b[1mMETHODS: \u001b[0mWe also performed exosome microRNA (miRNA) array analysis to explore a mechanistic insight into the effect of ASCs on PCa cell proliferation/apoptosis. \n",
      "\n",
      "\u001b[1mRESULTS: \u001b[0mBoth in vitro and in vivo experiments exhibited the inhibitory effect of ASCs on PC3M-luc2 cell proliferation, inducing apoptosis and PCa growth, respectively. Among upregulated miRNAs in ASCs compared with fibroblasts, we focused on miR-145, which was known as a tumor suppressor. ASC-derived conditioned medium (CM) significantly inhibited PC3M-luc2 cell proliferation, inducing apoptosis, but the effect was canceled by miR-145 knockdown in ASCs. ASC miR-145 knockdown CM also reduced the expression of Caspase 3/7 with increased antiapoptotic protein, BclxL, expression in PC3M-luc2 cells. \n",
      "\n",
      "\u001b[1mCONCLUSIONS: \u001b[0mThis study provides preclinical data that ASCs inhibit PCa growth, inducing PCa cell apoptosis with reduced activity of BclxL, at least in part, by miR-145, including exosomes released from ASCs, suggesting that ASC administration could be a novel and promising therapeutic strategy in patients with PCa. "
     ]
    }
   ],
   "source": [
    "get_results(test_abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ›  Exercises\n",
    "\n",
    "1. Train `model_5` on all of the data in the training dataset for as many epochs until it stops improving. Since this might take a while, you might want to use:\n",
    "  * [`tf.keras.callbacks.ModelCheckpoint`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) to save the model's best weights only.\n",
    "  * [`tf.keras.callbacks.EarlyStopping`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) to stop the model from training once the validation loss has stopped improving for ~3 epochs.\n",
    "2. Checkout the [Keras guide on using pretrained GloVe embeddings](https://keras.io/examples/nlp/pretrained_word_embeddings/). Can you get this working with one of our models?\n",
    "  * Hint: You'll want to incorporate it with a custom token [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer.\n",
    "  * It's up to you whether or not you fine-tune the GloVe embeddings or leave them frozen.\n",
    "3. Try replacing the TensorFlow Hub Universal Sentence Encoder pretrained  embedding for the [TensorFlow Hub BERT PubMed expert](https://tfhub.dev/google/experts/bert/pubmed/2) (a language model pretrained on PubMed texts) pretrained embedding. Does this effect results?\n",
    "  * Note: Using the BERT PubMed expert pretrained embedding requires an extra preprocessing step for sequences (as detailed in the [TensorFlow Hub guide](https://tfhub.dev/google/experts/bert/pubmed/2)).\n",
    "  * Does the BERT model beat the results mentioned in this paper? https://arxiv.org/pdf/1710.06071.pdf \n",
    "4. What happens if you were to merge our `line_number` and `total_lines` features for each sequence? For example, created a `X_of_Y` feature instead? Does this effect model performance?\n",
    "  * Another example: `line_number=1` and `total_lines=11` turns into `line_of_X=1_of_11`.\n",
    "5. Write a function (or series of functions) to take a sample abstract string, preprocess it (in the same way our model has been trained), make a prediction on each sequence in the abstract and return the abstract in the format:\n",
    "  * `PREDICTED_LABEL`: `SEQUENCE`\n",
    "  * `PREDICTED_LABEL`: `SEQUENCE`\n",
    "  * `PREDICTED_LABEL`: `SEQUENCE`\n",
    "  * `PREDICTED_LABEL`: `SEQUENCE`\n",
    "  * ...\n",
    "    * You can find your own unstrcutured RCT abstract from PubMed or try this one from: [*Baclofen promotes alcohol abstinence in alcohol dependent cirrhotic patients with hepatitis C virus (HCV) infection*](https://pubmed.ncbi.nlm.nih.gov/22244707/)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
